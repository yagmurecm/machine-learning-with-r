---
title: "Bitirme"
output:
  word_document: default
  html_document: default
editor_options: 
  chunk_output_type: inline
---
#Libraries
```{r}
library(tidyverse) #view() 
library(missForest) 
library(dplyr)
library(mice)
library(caret)
library(tidyverse)
library(AppliedPredictiveModeling)
library(pls) #kismi en kucuk kareler ve pcr icin
library(elasticnet)
library(broom) #tidy model icin
library(glmnet)
library(MASS)
library(ISLR)
library(PerformanceAnalytics)
library(funModeling)
library(Matrix) 
library(kernlab) #svm
library(e1071) #svm icin
library(rpart) #cart icin
library(pgmm) #olive data seti icin 
library(dslabs)
library(rpart.plot) #rpart gorsel icin
library(partykit) #karar agaci gorseli icin 
library(ipred) #bagging icin 
library(randomForest)
library(gbm)
library(nnet)
library(neuralnet)
library(GGally)
library(NeuralNetTools) #garson fonksiyonu icin
library(FNN)
library(DMwR)
library(pROC)
library(ROCR)
library(neuralnet)
library(rpart)
library(cli)
library(tree)
library(rpart.plot)
library(xgboost)
library(DiagrammeR)
library(mlbench)
library(class)#knn icin
library(cluster)
library(factoextra)
library(gridExtra)
library(MLmetrics)
library(car)
library(caTools)
#install.packages("MASS")
library(xgboost)

```

#VERİ IMPORTU
```{r}
df<-Veri_normal_oksijenli2
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hastane_Adi","Cinsiyet","Hasta_Takip_Durumu", "Vaka_Durumu","Temaslı_mi","Gebe_Mi","Bildirim_İlcesi","Yogun_Bakimda_Mi","Entübasyon_Var_mi","Yas","BT_Sonucu","BT","Pnomoni", "Sürec_Durumu", "Mernis_il","Mernis_ilce","Mernis_mahalle","Ferritin","CRP","Oksijen")
#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Gebe_Mi`))
df$`Gebe_Mi`[indeks_eksikgebelik] <- "Hayır"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`BT_Sonucu`))
df$`BT_Sonucu`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


#Hastane_Adi + Cinsiyet + Hasta_Takip_Durumu + Vaka_Durumu + Temaslı_mi + Gebe_Mi + Bildirim_İlcesi + Yogun_Bakimda_Mi + Entübasyon_Var_mi + Yas + BT_Sonucu + BT + Pnomoni + Sürec_Durumu + Mernis_il + Mernis_ilce + Mernis_mahalle + Ferritin + CRP + Oksijen

#Hastane_Adi , Cinsiyet , Hasta_Takip_Durumu , Vaka_Durumu , Temaslı_mi , Gebe_Mi , Bildirim_İlcesi , Yogun_Bakimda_Mi , Entübasyon_Var_mi , Yas , BT_Sonucu , BT , Pnomoni , Sürec_Durumu , Mernis_il , Mernis_ilce , Mernis_mahalle , Ferritin , CRP , Oksijen

```

##Veriye Genel Bakış
```{r}
summary(df)
glimpse(df)
```

#EKSİK VERİ ANALİZİ
##Eksik Verilerin Belirlenmesi
```{r}
indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)

indeks_eksiktakipdurumu <- which(is.na(df$`Hasta_Takip_Durumu`))
length(indeks_eksiktakipdurumu)

indeks_eksikgebelik <- which(is.na(df$`Gebe_Mi`))
length(indeks_eksikgebelik)

indeks_eksikyoğunb <- which(is.na(df$`Yogun_Bakimda_Mi`))
length(indeks_eksikyoğunb)

indeks_eksikentube <- which(is.na(df$`Entübasyon_Var_mi`))
length(indeks_eksikentube)

indeks_eksikbtsonuc <- which(is.na(df$`BT_Sonucu`))
length(indeks_eksikbtsonuc)

indeks_eksikmeril <- which(is.na(df$`Mernis_il`))
length(indeks_eksikmeril)

indeks_eksikmerilce <- which(is.na(df$`Mernis_ilce`))
length(indeks_eksikmerilce)

indeks_eksikmermah <- which(is.na(df$`Mernis_mahalle`))
length(indeks_eksikmermah)
```

##Faktörlerin derecelendirilmesi
```{r}

df$`Hasta_Takip_Durumu` <- factor(df$`Hasta_Takip_Durumu` , 
                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
                                ordered = T
                                )

df$`Vaka_Durumu` <- factor(df$`Vaka_Durumu` , 
                                levels = c("Kötü","Orta","İyi"),
                                ordered = T
                                )
df$`Gebe_Mi` <- factor(df$`Gebe_Mi` , 
                                levels = c("Evet" , "Hayır"),
                                ordered = T
                                )
df$`Yogun_Bakimda_Mi` <- factor(df$`Yogun_Bakimda_Mi` , 
                                levels = c("Evet" , "Hayır"),
                                ordered =T
                                )
df$`Pnomoni` <- factor(df$`Pnomoni` , 
                                levels = c("VAR" , "YOK"),
                                ordered = T
                                )
df$`BT` <- factor(df$`BT` , 
                                levels = c("VAR" , "YOK"),
                                ordered = T
                                )
```

#DOĞRUSAL REGRESYON

#1. Basit Doğrusal Regresyon
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


#df$`Patient_Followup_Status` <- factor(df$`Patient_Followup_Status` , 
#                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
#                                ordered = T
#                                )

df$`Case_Status` <- factor(df$`Case_Status` , 
                                levels = c("Bad","Medium","Good"),
                                ordered = T
                                )
df$`Pregnancy` <- factor(df$`Pregnancy` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`Intensive_care` <- factor(df$`Intensive_care` , 
                                levels = c("Yes" , "No"),
                                ordered =T
                                )
df$`Pneumonia` <- factor(df$`Pneumonia` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`CT` <- factor(df$`CT` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
```

##Regresyon Modeli Oluşturma
```{r}
df<- df%>% dplyr :: select(c("Age", "CRP", "Ferritin", "Oxygen"))

chart.Correlation(df, histogram=TRUE, pch=19)

set.seed(3456)
train_indeks <- createDataPartition(df$CRP, 
                                  p = .8, 
                                  list = FALSE, 
                                  times = 1)


train <- df[train_indeks,]
test  <- df[-train_indeks,]


train_x <- train %>% dplyr::select(-CRP)
train_y <- train$CRP
test_x <- test %>% dplyr::select(-CRP)
test_y <- test$CRP


#tek bir veri seti
training <- data.frame(train_x, CRP = train_y)

plot(CRP ~ Oxygen , data = df)

model <- lm(CRP ~ Oxygen , data = train)

model

# y = 98.2209 - 0.3508Yas 

summary(model)
defaultSummary(data.frame(obs = df$Oksijen,pred = as.vector(predict(model, df))))


#Multiple R-squared yüksekse model iyi çalışır demektir.
#Adjusted R-squared yüksekse model iyi çalışır demektir. Modele daha fazla bağımsız değişken eklenecekse adjusted daha güvenilir sonuçlar verir.
#p<0,05 olduğunda anlamlı bir model diyebiliriz.


# Ho : paramterenin anlamlı bir etkisi yoktur
# ha : anlamlı etkisi
```

## Artık Değerler

```{r}
artık <- as.numeric(model$residuals)
plot(artık)

plot(model)

```
## Mahalonobis Distance Aykırı Değer Kontrolü (KOYMA)

```{r}
plot(df$Oksijen  ,  df$CRP)
summary(model)
df2 <- na.omit(df[c("Oksijen" , "CRP")])
View(df2)
df2.center = colMeans(df2)
df2.center
df2.cov = cov(df2)
df2.cov

distance <- mahalanobis(df2 , center = df2.center , cov = df2.cov)

cutoff <- qchisq(p = 0.95 , df = 2)
cutoff

index <- which(distance > cutoff)
df2[index,]

df2_new <- df2[-index , ]

model2 <- lm(Oksijen ~ CRP , data  = df2_new)
model2
model

summary(model2)
plot(model2)
```
##Dönüşümler (KOYMA)
```{r}

par(mfrow=c(2,2))

model_log <- lm(Oksijen ~ log(CRP) , data = df)
summary(model_log)

plot(model_log)
dev.off()


model_sqrt <- lm(Oksijen ~ sqrt(CRP) , data = df)
summary(model_sqrt)

plot(model_log)


model_sqrt <- lm(sqrt(Oksijen) ~ sqrt(CRP) , data = df)
summary(model_sqrt)
plot(model_sqrt)




```
## Model Üzerindeden Tahminler
```{r}

#İLK MODELE GÖRE
predict(model , data.frame(CRP = c(2 , 1, 1.5, 10)))

view(df)
#ALTTAKİLER DİĞER MODELLERE GÖRE

model_log <- lm(log(Oksijen) ~ CRP , data = df)
summary(model_log)
predict(model2 , data.frame(CRP = c(2)))

# Log model üzerinden
predict <- predict(model_log , data.frame(CRP = c(2)))
exp(predict)

# Log model bağımsız değişken
model_log_bag <- lm(Oksijen ~ log(CRP) , data = airquality)
predict(model_log_bag , data.frame(CRP = c(74)))

## Bağımsız değişken için tekrar ters dönüşüm uygulanmaz
predict(model_log_bag , data.frame(CRP = c(exp(74)))) # hatalı kullanım

## Birden fazla değer ile tahmin
predict(model_log_bag , data.frame(CRP = c(2 , 1, 1.5, 10)))

```


#2. Çoklu Doğrusal Regresyon
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


#df$`Patient_Followup_Status` <- factor(df$`Patient_Followup_Status` , 
#                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
#                                ordered = T
#                                )

df$`Case_Status` <- factor(df$`Case_Status` , 
                                levels = c("Bad","Medium","Good"),
                                ordered = T
                                )
df$`Pregnancy` <- factor(df$`Pregnancy` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`Intensive_care` <- factor(df$`Intensive_care` , 
                                levels = c("Yes" , "No"),
                                ordered =T
                                )
df$`Pneumonia` <- factor(df$`Pneumonia` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`CT` <- factor(df$`CT` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
```
##Veri 
```{r} 

df<- df %>% dplyr::select(-c("Hospital", "Notification_District", "Province", "District", "Neighborhood"))

df2 <- df[c("Age" ,  "CRP" , "Oxygen" , "Case_Status" , "Intubation" ,"Ferritin", "Intensive_care")]

df3 <- df[c("Age" ,  "CRP" , "Oxygen" , "Case_Status" , "Intubation" )]

df4 <- df[c("Sex","Patient_Followup_Status", "Case_Status","Contact","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status","Ferritin","CRP","Oxygen")]

data_drop <- droplevels(df)                  # Drop levels of data frame
data_drop2 <- droplevels(df2)
data_drop3 <- droplevels(df3)
data_drop4 <- droplevels(df4)

```

##Model
```{r}
str(df)
str(data_drop)

#model1
set.seed(145)
sampleIndex <- sample(1:nrow(df) , size = 0.8*nrow(df))

trainSet <- df[sampleIndex , ]
testSet <- df[-sampleIndex , ]

model1 <- lm(CRP ~ . , data  = trainSet)
summary(model1)

#model2
set.seed(145)
sampleIndex2 <- sample(1:nrow(df2) , size = 0.8*nrow(df2))

trainSet2 <- df2[sampleIndex2 , ]
testSet2 <- df2[-sampleIndex2 , ]

model2 <- lm(CRP ~ . , data  = trainSet2)
summary(model2)

#model3
set.seed(145)
sampleIndex3 <- sample(1:nrow(df3) , size = 0.8*nrow(df3))

trainSet3 <- df3[sampleIndex3 , ]
testSet3 <- df3[-sampleIndex3 , ]

model3 <- lm(CRP ~ . , data  = trainSet3)
summary(model3)

#model4
set.seed(145)
sampleIndex4 <- sample(1:nrow(df4) , size = 0.8*nrow(df4))

trainSet4 <- df4[sampleIndex4 , ]
testSet4 <- df4[-sampleIndex4 , ]

model4 <- lm(CRP ~  Cinsiyet + Hasta_Takip_Durumu + Vaka_Durumu + Temaslı_mi   + Yogun_Bakimda_Mi + Entübasyon_Var_mi + Yas + BT_Sonucu + BT + Pnomoni + Sürec_Durumu + Ferritin  + Oksijen , data  = trainSet4)
summary(model4)

#Model Drop1
set.seed(145)
sampleIndexdrop <- sample(1:nrow(data_drop) , size = 0.8*nrow(data_drop))

trainSetdrop <- data_drop[sampleIndexdrop , ]
testSetdrop <- data_drop[-sampleIndexdrop , ]

modelDrop1 <- lm(CRP ~ . , data  = trainSetdrop)
summary(modelDrop1)
#Model Drop2
set.seed(145)
sampleIndexdrop2 <- sample(1:nrow(data_drop2) , size = 0.8*nrow(data_drop2))

trainSetdrop2 <- data_drop2[sampleIndexdrop2 , ]
testSetdrop2 <- data_drop2[-sampleIndexdrop2 , ]

modelDrop2 <- lm(CRP ~ . , data  = trainSetdrop2)
summary(modelDrop2)
#Model Drop3
set.seed(145)
sampleIndexdrop3 <- sample(1:nrow(data_drop3) , size = 0.8*nrow(data_drop3))

trainSetdrop3 <- data_drop3[sampleIndexdrop3 , ]
testSetdrop3 <- data_drop3[-sampleIndexdrop3 , ]

modelDrop3 <- lm(CRP ~ . , data  = trainSetdrop3)
summary(modelDrop3)
#Model Drop4
set.seed(145)
sampleIndexdrop4 <- sample(1:nrow(data_drop4) , size = 0.8*nrow(data_drop4))

trainSetdrop4 <- data_drop4[sampleIndexdrop4 , ]
testSetdrop4 <- data_drop4[-sampleIndexdrop4 , ]

modelDrop4 <- lm(CRP ~ . , data  = trainSetdrop4)
summary(modelDrop4)
# model2 <- lm(CRP ~ Yas + Ferritin  + Vaka_Durumu + Entübasyon_Var_mi + Yogun_Bakimda_Mi + Oksijen , data  = trainSet)

#"Cinsiyet","Hasta_Takip_Durumu", "Vaka_Durumu","Temaslı_mi","Yogun_Bakimda_Mi","Entübasyon_Var_mi","Yas","BT_Sonucu","BT","Pnomoni", "Sürec_Durumu","Ferritin","CRP","Oksijen"

AIC(model1 , k = 21)
AIC(model2 , k = 9)
AIC(model3 , k = 7)
AIC(model4 , k = 15)
#model 4 en az

BIC(model1)
BIC(model2)
BIC(model3)
BIC(model4)
#model 4 en az

# Artık plotları 
plot(model4)

#k = parametre sayısı+ intercept(1)+ varyans(1)
AIC(modelDrop1 , k = 21)
AIC(modelDrop2 , k = 9)
AIC(modelDrop3 , k = 7)
AIC(modelDrop4 , k = 15)
#model 4 en az

BIC(modelDrop1)
BIC(modelDrop2)
BIC(modelDrop3)
BIC(modelDrop4)

#model5 DROPTERM FUNC
dropterm(model1, test="F")


set.seed(145)
sampleIndex5 <- sample(1:nrow(df) , size = 0.8*nrow(df))

trainSet5 <- df[sampleIndex5 , ]
testSet5 <- df[-sampleIndex5 , ]

model5 <- lm(CRP ~  Case_Status+ Intubation + CT_Result + CT + Process_Status + Oxygen, data  = trainSet5)
summary(model5)

#model5 <- lm(CRP ~  Cinsiyet+Vaka_Durumu  + BT_Sonucu + BT + Mernis_ilce+Mernis_mahalle+Ferritin+ Oksijen, data  = trainSet5)

summary(model5)
dropterm(model5, test="F")

AIC(model5 , k =8)
BIC(model5)


defaultSummary(data.frame(obs = trainSet5$CRP,pred = as.vector(predict(model5, trainSet5))))


defaultSummary(data.frame(obs = testSet5$CRP,pred = as.vector(predict(model5, testSet5))))
```

##Tahmin
```{r}

predictions <- predict(model5 , testSet5)

#Gerçek değerler ile predictionlar arasındaki fark
#R2(predictions , testSet4$CRP)
RMSE(predictions , testSet5$CRP)
MAE(predictions , testSet5$CRP)

RSQUARE = function(y_actual,y_predict){
  cor(y_actual,y_predict)^2
}
RSQUARE(testSet5$CRP,predict(model5,testSet5))


predictions <- predict(model5 , testSet5)
R2(predictions ,  testSet5$CRP)

```

##Aykırı Değerlerin Tespiti
```{r}
# Cook's Distance 

dist <- cooks.distance(model5)
olcut1 <- mean(dist)*3
olcut2 <- 4 / length(dist)

olcut1Index <- which(dist > olcut1)
olcut2Index <- which(dist > olcut2)

olcut1
length(olcut1Index)
length(olcut2Index)


plot(1:length(dist) , dist , type="p" , ylim = range(dist)*c(1,0.07))
abline( h = olcut1 , col = "red")


trainSetRemovedOut <- trainSet5[-olcut1Index , ]
```

## Model Kaşılaştırmaları

```{r}

#Aykırı değerlerin atıldığı veri seti ile oluşturulan model
model6 <- lm(CRP ~  Case_Status+ Intubation + CT_Result + CT + Process_Status + Oxygen, data  = trainSetRemovedOut)

summary(model6)
summary(model5)

AIC(model6, k = 8)
BIC(model6)
AIC(model3 , k = 7)
BIC(model3)

# Yeni Model (aykırı gözlemlerin çıkarıldığı)
predictions6 <- predict(model6 , testSet5)
#R2(predictions5 ,  testSet4$CRP)
RMSE(predictions6 , testSet5$CRP)
MAE(predictions6 , testSet5$CRP)



defaultSummary(data.frame(obs = trainSetRemovedOut$CRP,pred = as.vector(predict(model6, trainSetRemovedOut))))

defaultSummary(data.frame(obs = testSet5$CRP,pred = as.vector(predict(model6, testSet5))))



# Eski Model
predictions <- predict(model4 , testSet4)
#R2(predictions ,  testSet4$CRP)
RMSE(predictions ,  testSet4$CRP)
MAE(predictions ,  testSet4$CRP)

defaultSummary(data.frame(obs = testSet4$CRP,pred = as.vector(predict(model4, testSet4))))


```
## VIF Varyans Şişkinlik Faktörü (HATA VERİYOR)
```{r}
#Çoklu bağlantılılık sorununu tespit etmek için kullanılır.


?vif
vif(model6)

modelVif1 <- lm(Humidity9am ~ MinTemp + MaxTemp + 
               Rainfall + WindSpeed9am , data  = trainSetRemovedOut)
vif(modelVif1)

summary(modelVif1)
summary(model5)


modelVif2 <- lm(Humidity9am ~ MinTemp + Temp9am + 
                  Rainfall + WindSpeed9am , data  = trainSetRemovedOut)
vif(modelVif2)
summary(modelVif2)


modelVif3 <- lm(Humidity9am ~ Temp9am + 
                  Rainfall + WindSpeed9am , data  = trainSetRemovedOut)

vif(modelVif3)
summary(modelVif3)

# Test veri seti üzerinden model değerlendirme 
predictionsVif3 <- predict(modelVif3 , testSet2)
R2(predictionsVif3 , testSet2$Humidity9am)
RMSE(predictionsVif3 , testSet2$Humidity9am)
MAE(predictionsVif3 , testSet2$Humidity9am)

predictionsVif2 <- predict(modelVif2 , testSet2)
R2(predictionsVif2 , testSet2$Humidity9am)
RMSE(predictionsVif2 , testSet2$Humidity9am)
MAE(predictionsVif2 , testSet2$Humidity9am)

predictionsVif1 <- predict(modelVif1 , testSet2)
R2(predictionsVif1 , testSet2$Humidity9am)
RMSE(predictionsVif1 , testSet2$Humidity9am)
MAE(predictionsVif1 , testSet2$Humidity9am)


```

## Aşamalı Regresyon StepWise Regression 

```{r}

model1 <- lm( CRP ~ Hastane_Adi + Cinsiyet + Hasta_Takip_Durumu + Vaka_Durumu + Temaslı_mi + Gebe_Mi + Bildirim_İlcesi + Yogun_Bakimda_Mi + Entübasyon_Var_mi + Yas + BT_Sonucu + BT + Pnomoni + Sürec_Durumu + Mernis_il + Mernis_ilce + Mernis_mahalle + Ferritin  + Oksijen
 , data  = trainSet)

#step fonksiyonunda kullanılan 1, modeli ilk önce intercept ile kur anlamına gelmektedir.
##SONUÇ: lm(formula = CRP ~ Vaka_Durumu + BT + Entübasyon_Var_mi + BT_Sonucu , data = df)
step(lm(CRP ~ 1 , data = trainSetRemovedOut) , direction = "forward" ,scope = ~ Hastane_Adi + Cinsiyet + Hasta_Takip_Durumu + Vaka_Durumu + Temaslı_mi + Gebe_Mi + Bildirim_İlcesi + Yogun_Bakimda_Mi + Entübasyon_Var_mi + Yas + BT_Sonucu + BT + Pnomoni + Sürec_Durumu + Mernis_il + Mernis_ilce + Mernis_mahalle + Ferritin  + Oksijen)


##SONUÇ: lm(formula = CRP ~ Vaka_Durumu + BT + Entübasyon_Var_mi + Mernis_il + Mernis_ilce + Oksijen + BT_Sonucu + Yogun_Bakimda_Mi, data = df)
step(lm(CRP ~ 1 , data = df) , direction = "forward" , scope = ~ Hastane_Adi + Cinsiyet + Hasta_Takip_Durumu + Vaka_Durumu + Temaslı_mi + Gebe_Mi + Bildirim_İlcesi + Yogun_Bakimda_Mi + Entübasyon_Var_mi + Yas + BT_Sonucu + BT + Pnomoni + Sürec_Durumu + Mernis_il + Mernis_ilce + Mernis_mahalle + Ferritin  + Oksijen)


## Backward Geri DOğru gitme
##SONUÇ: lm(formula = CRP ~ Vaka_Durumu + Entübasyon_Var_mi + BT_Sonucu +     BT, data = trainSetRemovedOut)
step(lm(CRP ~ Hastane_Adi + Cinsiyet + Hasta_Takip_Durumu + Vaka_Durumu + Temaslı_mi + Gebe_Mi + Bildirim_İlcesi + Yogun_Bakimda_Mi + Entübasyon_Var_mi + Yas + BT_Sonucu + BT + Pnomoni + Sürec_Durumu + Mernis_il + Mernis_ilce + Mernis_mahalle + Ferritin  + Oksijen, data = trainSetRemovedOut) )

##SONUÇ:lm(formula = CRP ~ Cinsiyet + Vaka_Durumu + Yogun_Bakimda_Mi + Entübasyon_Var_mi + BT_Sonucu + BT + Mernis_il + Mernis_ilce +     Ferritin + Oksijen, data = df)
step(lm(CRP ~ Hastane_Adi + Cinsiyet + Hasta_Takip_Durumu + Vaka_Durumu + Temaslı_mi + Gebe_Mi + Bildirim_İlcesi + Yogun_Bakimda_Mi + Entübasyon_Var_mi + Yas + BT_Sonucu + BT + Pnomoni + Sürec_Durumu + Mernis_il + Mernis_ilce + Mernis_mahalle + Ferritin  + Oksijen , data = df) )

# Both / Çift Yönlü 
##SONUÇ:lm(formula = CRP ~ Vaka_Durumu + BT + Entübasyon_Var_mi + BT_Sonucu,  data = trainSetRemovedOut)
step(lm(CRP ~ 1 , data = trainSetRemovedOut) , direction = "both" , scope = ~ Hastane_Adi + Cinsiyet + Hasta_Takip_Durumu + Vaka_Durumu + Temaslı_mi + Gebe_Mi + Bildirim_İlcesi + Yogun_Bakimda_Mi + Entübasyon_Var_mi + Yas + BT_Sonucu + BT + Pnomoni + Sürec_Durumu + Mernis_il + Mernis_ilce + Mernis_mahalle + Ferritin  + Oksijen )

##SONUÇ: lm(formula = CRP ~ Vaka_Durumu + BT + Entübasyon_Var_mi + Mernis_il+  Mernis_ilce + Oksijen + BT_Sonucu + Yogun_Bakimda_Mi, data = df)
step(lm(CRP ~ 1 , data = df) , direction = "both" , scope = ~ Hastane_Adi + Cinsiyet + Hasta_Takip_Durumu + Vaka_Durumu + Temaslı_mi + Gebe_Mi + Bildirim_İlcesi + Yogun_Bakimda_Mi + Entübasyon_Var_mi + Yas + BT_Sonucu + BT + Pnomoni + Sürec_Durumu + Mernis_il + Mernis_ilce + Mernis_mahalle + Ferritin  + Oksijen )

# Model kaydetme
modelStep <- step(lm(CRP ~ 1 , data = trainSetRemovedOut) , direction = "both" , scope = ~ MinTemp + MaxTemp + Temp9am + 
       Rainfall + WindSpeed9am + Pressure9am )

modelStep
```

## Model Validasyon/Model Tuning
```{r}
trainSet5_y<-trainSet5$CRP
testSet5_y<-testSet5$CRP

ctrl <- trainControl(method = "cv", 
                     number = 10)

lm_val_fit <- train(x = trainSet5, y = trainSet5_y,
      method = "lm",
      trControl = ctrl)


lm_val_fit$results

summary(lm_val_fit)
names(lm_val_fit)
lm_val_fit$finalModel

defaultSummary(data.frame(obs = trainSet5$CRP,pred = as.vector(predict(lm_val_fit, trainSet5))))

defaultSummary(data.frame(obs = testSet5$CRP,pred = as.vector(predict(lm_val_fit, testSet5))))
```

#3. Ridge Regresyon
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


#df$`Patient_Followup_Status` <- factor(df$`Patient_Followup_Status` , 
#                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
#                                ordered = T
#                                )

df$`Case_Status` <- factor(df$`Case_Status` , 
                                levels = c("Bad","Medium","Good"),
                                ordered = T
                                )
df$`Pregnancy` <- factor(df$`Pregnancy` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`Intensive_care` <- factor(df$`Intensive_care` , 
                                levels = c("Yes" , "No"),
                                ordered =T
                                )
df$`Pneumonia` <- factor(df$`Pneumonia` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`CT` <- factor(df$`CT` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
```


## Veri Ön İşleme - Standartlaştırma #####

```{r}
names(df)

modelData<-df %>% dplyr::select(-c("Hospital","Notification_District","Province","District","Neighborhood"))

num_cols <- c("CRP" , "Ferritin", "Oxygen", "Age")

##Standartlaştırma İşlemi 
pre_scaled <- preProcess(modelData[, num_cols] , method = c("center" , "scale"))
## Standartlaştırılmış veri seti
modelDataScaled <- predict(pre_scaled , modelData)

```


##Veri Seti
```{r}
## One Hot Encoding Dummy Değişken

modelDataScaled1 <- model.matrix(CRP ~ . , data  = modelDataScaled)
#head(modelDataScaled1)

set.seed(145)
sampleTrainIndex <- sample(1:nrow(modelDataScaled1)  , size = 0.8*nrow(modelDataScaled1))

trainSet_x <- modelDataScaled1[sampleTrainIndex,]
testSet_x <- modelDataScaled1[-sampleTrainIndex,]

trainSet_y <- modelDataScaled$CRP[sampleTrainIndex]
testSet_y <- modelDataScaled$CRP[-sampleTrainIndex]

```


## Ridge REgresyon Modeli 
```{r}

modelRidge1 <- glmnet(trainSet_x , trainSet_y , alpha = 0 )
summary(modelRidge1)

plot(modelRidge1, xvar = "lambda", label = TRUE)
min(log(modelRidge1$lambda))
#modelRidge1$beta#beta katsayıları
###modelRidge1$a0#intercept
##modelRidge1$lambda#seçilen lambda değeri
modelRidge1$dev.ratio#R2 gibi yorumlanabilir. Büyük olası daha iyidir. =(1/(dev/null.dev))


defaultSummary(data.frame(obs = trainSet_y,pred = as.vector(predict(modelRidge1, as.matrix(trainSet_x)))))

defaultSummary(data.frame(obs = testSet_y,pred = as.vector(predict(modelRidge1, as.matrix(testSet_x)))))
```

## Lambda Değeri İçin Cross Validation (Tuning)
```{r}
#cv.glmnet fonksiyonu kullanılır.

#denenecek lambda değerleri için vektör oluşturulur.
lambdas = 10^seq(3 , -2 , by = -.01)

modelRidgeCV <- cv.glmnet(trainSet_x , trainSet_y , alpha = 1 , 
                          lambda = lambdas , nfolds = 10)

plot(modelRidgeCV)

# İdeal Lambda Değeri
modelRidgeCV$lambda.min
#modelRidgeCV$nzero

modelRidgeCV
#
```

## Model Tahmin Performans Değerlendirmesi
```{r}
#Bulunan lambda değeri ile model oluşturulur.
fitGl <- glmnet(trainSet_x , trainSet_y  , alpha = 0 , lambda = 0.01)

predictionsRidge <- predict(fitGl , testSet_x )
defaultSummary(data.frame(obs = trainSet_y,pred = as.vector(predict(fitGl, as.matrix(trainSet_x)))))
defaultSummary(data.frame(obs = testSet_y,pred = as.vector(predict(fitGl, as.matrix(testSet_x)))))

#R2(predictionsRidge , testSet_y)
MAE(predictionsRidge , testSet_y)
RMSE(predictionsRidge , testSet_y)

dfPred  <- data.frame(predicitons = predictionsRidge , actuals = testSet_y)

minMaxAc <- mean(apply(dfPred , 1 , min) / apply(dfPred , 1 , max)) 
minMaxAc



```

#4. Lasso Regresyon (L1)
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


#df$`Patient_Followup_Status` <- factor(df$`Patient_Followup_Status` , 
#                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
#                                ordered = T
#                                )

df$`Case_Status` <- factor(df$`Case_Status` , 
                                levels = c("Bad","Medium","Good"),
                                ordered = T
                                )
df$`Pregnancy` <- factor(df$`Pregnancy` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`Intensive_care` <- factor(df$`Intensive_care` , 
                                levels = c("Yes" , "No"),
                                ordered =T
                                )
df$`Pneumonia` <- factor(df$`Pneumonia` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`CT` <- factor(df$`CT` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
```

##Model
```{r}

modelData1<-df %>% dplyr::select(-c("Hospital","Notification_District","Province","District","Neighborhood"))

num_cols <- c("CRP" , "Ferritin", "Oxygen", "Age")

##Standartlaştırma İşlemi 
pre_scaled <- preProcess(modelData1[, num_cols] , method = c("center" , "scale"))
## Standartlaştırılmış veri seti
modelData <- predict(pre_scaled , modelData1) 

modelDataDummy <- model.matrix( ~ . , data  = modelData)

set.seed(155)
sampleTrainIndex <- sample(1:nrow(modelDataDummy) , size = 0.75*nrow(modelDataDummy))

trainData <- modelDataDummy[sampleTrainIndex , ]
testData <- modelDataDummy[-sampleTrainIndex , ]

####trainDataX <- trainData[, -c(1,606)]
###trainDataY <- trainData[, 606]

##testDataX <- testData[, -c(1,606)]
#testDataY <- testData[, 606]

trainDataX <- trainData[, -c(1,26)]
trainDataY <- trainData[, 26]

testDataX <- testData[, -c(1,26)]
testDataY <- testData[, 26]

lambdas <- 10^seq(2,-2 , by = -0.01)

fitGL <- glmnet(trainDataX , trainDataY , alpha = 1 , lambda = lambdas) 
fitGL

plot(fitGL , xvar = "lambda")

```

##Cross Validation (tuning)
```{r}
#nrow(trainDataX)
fitGLCV <- cv.glmnet(trainDataX , trainDataY , alpha = 1 , lambda = lambdas , nfolds = 10)
plot(fitGLCV)

best_lambda <- fitGLCV$lambda.min
best_lambda
```

##Model Tahmin Performans Değerlendirmesi 
```{r}
fitGlLasso <- glmnet(trainDataX , trainDataY , alpha = 1 , lambda = best_lambda) 

#fitGlLasso$beta
fitGlLasso

predictions <- predict(fitGlLasso , testDataX)

#R2(predictions , testDataY)
MAE(predictions , testDataY)
RMSE(predictions , testDataY)

defaultSummary(data.frame(obs = trainDataY,pred = as.vector(predict(fitGlLasso, as.matrix(trainDataX)))))

defaultSummary(data.frame(obs = testDataY,pred = as.vector(predict(fitGlLasso, as.matrix(testDataX)))))


fitGlOLS<- glmnet(trainDataX , trainDataY , alpha = 1 , lambda = 0)
fitGlOLS$beta


predictionsOLS <- predict(fitGlOLS , testDataX)

#R2(predictionsOLS , testDataY)
MAE(predictionsOLS , testDataY)
RMSE(predictionsOLS , testDataY)

defaultSummary(data.frame(obs = testDataY,pred = as.vector(predict(fitGlOLS, as.matrix(testDataX)))))
```

#5. Elastic Regresyon
(Hem Ridge hem de Lassonun uygulandığı yöntem)
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


#df$`Patient_Followup_Status` <- factor(df$`Patient_Followup_Status` , 
#                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
#                                ordered = T
#                                )

df$`Case_Status` <- factor(df$`Case_Status` , 
                                levels = c("Bad","Medium","Good"),
                                ordered = T
                                )
df$`Pregnancy` <- factor(df$`Pregnancy` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`Intensive_care` <- factor(df$`Intensive_care` , 
                                levels = c("Yes" , "No"),
                                ordered =T
                                )
df$`Pneumonia` <- factor(df$`Pneumonia` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`CT` <- factor(df$`CT` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
```

##Veri Seti
```{r}

modelData1<-df %>% dplyr::select(-c("Hospital","Notification_District","Province","District","Neighborhood"))

num_cols <- c("CRP" , "Ferritin", "Oxygen", "Age")

##Standartlaştırma İşlemi 
pre_scaled <- preProcess(modelData1[, num_cols] , method = c("center" , "scale"))
## Standartlaştırılmış veri seti
modelData <- predict(pre_scaled , modelData1) 

modelDataDummy <- model.matrix( ~ . , data  = modelData)

trainDataX <- trainData[, -c(1,26)]
trainDataY <- trainData[, 26]

testDataX <- testData[, -c(1,26)]
testDataY <- testData[, 26]

lambdas <- 10^seq(2,-2 , by = -0.01)

fitGL <- glmnet(trainDataX , trainDataY , alpha = 1 , lambda = lambdas) 
fitGL

plot(fitGL , xvar = "lambda")

```

## Elastic Net Regression  Model Oluşturma 
```{r}
fitElastic<- glmnet(trainDataX , trainDataY , alpha = 0.5 , lambda = lambdas)
fitElastic

plot(fitElastic , xvar = "lambda")

# cv.glmnet()
```

## Elastic Net Cross Validation  (Tuning)
Alpha ve lambda değerleri için cv
```{r}
trControl = trainControl(method = "repeatedcv" , number = 10 , 
             repeats = 5 , 
             search = "random",
             verboseIter = TRUE , )


fitElasCV <- train(trainDataX , trainDataY ,  method = "glmnet" , 
                   tuneLength = 30 , 
                   trControl = trControl)

#fitElasCV
fitElasCV$bestTune
#fitElasCV$finalModel

#alpha 0.9157278
#lambda 0.01188862

## Elastic Net Cross Validation Alpha ve Lambda Değerleri İle

trControlGrid = trainControl(method = "repeatedcv" , number = 3 , 
                         repeats = 5 , 
                         verboseIter = TRUE , )

gridAlphaLambda <- expand.grid(
                                .lambda = seq(0 , 0.5 , by = 0.01),
                                .alpha = seq(0 , 3 , by= 0.01) 
                                )
#gridAlphaLambda

fitElasCVGrid <- train(trainDataX , trainDataY ,  method = "glmnet" , 
                   tuneGrid = gridAlphaLambda , 
                   trControl = trControl)
fitElasCVGrid$bestTune
#alpha 1
#lambda 0.01
#fitElasCVGrid$finalModel

modelLookup(model = "glmnet")
```
## Tahmin ve Değerlendirme
```{r}
fitElasCV$bestTune

predictModel <- glmnet(trainDataX , trainDataY , alpha = 0.9625183 , lambda = 0.006940991 )

predictions_1 <- predict(predictModel , testDataX )
#predictions_1

defaultSummary(data.frame(obs = trainDataY,pred = as.vector(predict(fitElasCV, as.matrix(trainDataX)))))


defaultSummary(data.frame(obs = testDataY,pred = as.vector(predict(fitElasCV, as.matrix(testDataX)))))

caret::R2(predictions_1 , testDataY)
caret::RMSE(predictions_1 , testDataY)
caret::MAE(predictions_1 , testDataY)

fitElasCVGrid$bestTune

predictModel_grid <- glmnet(trainDataX , trainDataY , alpha = 1 , lambda = 0.1 )

predictions_grid <- predict(predictModel_grid , testDataX )
#predictions_1

defaultSummary(data.frame(obs = trainDataY,pred = as.vector(predict(fitElasCVGrid, as.matrix(trainDataX)))))


defaultSummary(data.frame(obs = testDataY,pred = as.vector(predict(fitElasCVGrid, as.matrix(testDataX)))))
## EKK karşılaştırması 

#predictions_EKK <- predict(fitGlOLS , testDataX )
#predictions_EKK

#caret::R2(predictions_EKK , testDataY)
#caret::RMSE(predictions_EKK , testDataY)
#caret::MAE(predictions_EKK , testDataY)
```

#6. PCR
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


#df$`Patient_Followup_Status` <- factor(df$`Patient_Followup_Status` , 
#                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
#                                ordered = T
#                                )

df$`Case_Status` <- factor(df$`Case_Status` , 
                                levels = c("Bad","Medium","Good"),
                                ordered = T
                                )
df$`Pregnancy` <- factor(df$`Pregnancy` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`Intensive_care` <- factor(df$`Intensive_care` , 
                                levels = c("Yes" , "No"),
                                ordered =T
                                )
df$`Pneumonia` <- factor(df$`Pneumonia` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`CT` <- factor(df$`CT` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
```


```{r}

df<- df %>% dplyr::select(c("Sex","Pregnancy", "Patient_Followup_Status", "Case_Status", "Contact", "Intensive_care", "Intubation", "Age", "CT_Result", "CT","CRP","Pneumonia", "Ferritin", "Oxygen","Process_Status"))


#train setin indeksini oluşturma
set.seed(3456)
train_indeks <- createDataPartition(df$CRP, 
                                    p = .8, 
                                    list = FALSE, 
                                    times = 1)
#train set oluşturma
train <- df[train_indeks, ]
#test set oluşturma
test <- df[-train_indeks, ]


#bir veri setini sadece train ve set olarak ikiye ayırmak model çalışmalarında karmaşıklık yaratır. train ve test setlerinin içindeki bağımlı ve bağımsız değişkenlerin ayrı ayrı seçilmeli 
train_x <- train %>% dplyr::select(-CRP)
train_y <- train$CRP


test_x <- test %>% dplyr::select(-CRP)
test_y <- test$CRP


training <- data.frame(train_x, CRP = train_y)
```



##model
```{r}

pcr_fit <- pcr(CRP~  Sex + Pregnancy  +  Patient_Followup_Status  +  Case_Status  +  Contact  +  Intensive_care  +  Intubation  +  Age  +  CT_Result  +  CT  + Pneumonia  +  Ferritin  +  Oxygen     , data = training,    scale = TRUE,    validation = "CV")

summary(pcr_fit)

pcr_fit$method
?pcr
# ya da
#pcr_fit <- pcr(CRP~ Yas+ Ferritin + Oksijen, data = training,    scale = TRUE,    validation = "CV")

#değişken sayısına göre hata kareleri ortalaması
validationplot(pcr_fit, val.type = "MSEP")

```

##train hatasının hesaplanması
```{r}
defaultSummary(data.frame(obs = training$CRP,
pred = as.vector(pcr_fit$fitted.values))
)
```

##tahmin
```{r}

predict(pcr_fit, test_x[1:10,], ncomp = 1:2)

```

##test hatasının hesaplanması
```{r}
defaultSummary(data.frame(obs = test_y,
pred = as.vector(predict(pcr_fit, test_x, ncomp =1:3))))
```
##Model Tunning

```{r}


ctrl <- trainControl(method = "cv", number = 10)
set.seed(100)

pcr_tune <- train(train_x, train_y,
                  method = "pcr",
                  trControl = ctrl,
                  preProc = c("center", "scale"))
#model ciktisi
pcr_tune
#ncomp:3 çıkıyor


pcr_tune2 <- train(train_x, train_y,
                  method = "pcr",
                  trControl = ctrl,
                  tuneLength = 20,
                  preProc = c("center", "scale"))

pcr_tune2
#ncomp:9 çıkıyor

plot(pcr_tune2)

pcr_tune2$finalModel

```

Model Test Hatasi
```{r}

defaultSummary(data.frame(obs = train_y,
pred = as.vector(predict(pcr_tune2, train_x)))
)

defaultSummary(data.frame(obs = test_y,
pred = as.vector(predict(pcr_tune2, test_x)))
)

```

#7. Kismi En Kucuk Kareler Regresyonu 
(Partial Least Squares)


pls kutuphanesi kismi en kucuk kareler regresyonu ve temel bilesen regresyonu icin fonksiyonlar sagliyor. 2007 yilinda Mevik ve Wehrens isimli dunya vatandaslarinda yazilmis.


pls kutuphanesi on tanimli olarak Dayal ve MacGregor'un 1994, kernel algoritmasini kullaniliyor. method argumani ile bu algoritma degistirilebilir. 
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


#df$`Patient_Followup_Status` <- factor(df$`Patient_Followup_Status` , 
#                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
#                                ordered = T
#                                )

df$`Case_Status` <- factor(df$`Case_Status` , 
                                levels = c("Bad","Medium","Good"),
                                ordered = T
                                )
df$`Pregnancy` <- factor(df$`Pregnancy` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`Intensive_care` <- factor(df$`Intensive_care` , 
                                levels = c("Yes" , "No"),
                                ordered =T
                                )
df$`Pneumonia` <- factor(df$`Pneumonia` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`CT` <- factor(df$`CT` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
```

```{r}

df<-df %>% dplyr::select(-c("Hospital","Notification_District","Province","District","Neighborhood"))

#train setin indeksini oluşturma
set.seed(3456)
train_indeks <- createDataPartition(df$CRP, 
                                    p = .8, 
                                    list = FALSE, 
                                    times = 1)
#train set oluşturma
train <- df[train_indeks, ]
#test set oluşturma
test <- df[-train_indeks, ]


#bir veri setini sadece train ve set olarak ikiye ayırmak model çalışmalarında karmaşıklık yaratır. train ve test setlerinin içindeki bağımlı ve bağımsız değişkenlerin ayrı ayrı seçilmeli 
train_x <- train %>% dplyr::select(-CRP)
train_y <- train$CRP


test_x <- test %>% dplyr::select(-CRP)
test_y <- test$CRP


training <- data.frame(train_x, CRP = train_y)

```

## Model 

```{r}

pls_fit <- plsr(CRP~., data  = training)

summary(pls_fit)

validationplot(pls_fit, val.type = "MSEP")

names(pls_fit)


```

## Tahmin 


```{r}

predict(pls_fit, test_x[1:10,], ncomp = 1:2)

defaultSummary(data.frame(obs = train_y,
pred = as.vector(predict(pls_fit, train_x)))
)

defaultSummary(data.frame(obs = test_y,
pred = as.vector(predict(pls_fit, test_x)))
)

```

## Model Tuning 

```{r}


ctrl <- trainControl(method = "cv", number = 10)
set.seed(100)


pls_tune <- train(train_x, train_y,
                  method = "pls",
                  trControl = ctrl,
                  tuneLength = 20,
                  preProc = c("center", "scale"))

plot(pls_tune)

pls_tune$results

defaultSummary(data.frame(obs = train_y,
pred = as.vector(predict(pls_tune, train_x)))
)

defaultSummary(data.frame(obs = test_y,
pred = as.vector(predict(pls_tune, test_x)))
)


```

#NONLİNEER REGRESYON

#1. KNN
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


#df$`Patient_Followup_Status` <- factor(df$`Patient_Followup_Status` , 
#                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
#                                ordered = T
#                                )

df$`Case_Status` <- factor(df$`Case_Status` , 
                                levels = c("Bad","Medium","Good"),
                                ordered = T
                                )
df$`Pregnancy` <- factor(df$`Pregnancy` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`Intensive_care` <- factor(df$`Intensive_care` , 
                                levels = c("Yes" , "No"),
                                ordered =T
                                )
df$`Pneumonia` <- factor(df$`Pneumonia` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`CT` <- factor(df$`CT` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
```

##veri seti
```{r}
df <- df %>% dplyr::select(-c("Hospital", "Notification_District", "CT_Result", "Process_Status", "Province", "District", "Neighborhood"))

df$Case_Status <- ifelse(df$Case_Status=="Bad",0,ifelse(df$Case_Status=="Medium",1,2))
df$Sex <- ifelse(df$Sex=="Female",0,1)
df$Patient_Followup_Status <- ifelse(df$Patient_Followup_Status=="Home Isolation/Ambulatory",0,1)
df$Contact <- ifelse(df$Contact=="Yes",0,1)
df$Pregnancy <- ifelse(df$Pregnancy=="Yes",0,1)
df$Intensive_care <- ifelse(df$Intensive_care=="Yes",0,1)
df$Intubation <- ifelse(df$Intubation=="Yes",0,1)
df$CT <- ifelse(df$CT=="Yes",0,1)
df$Pneumonia <- ifelse(df$Pneumonia=="Yes",0,1)


rownames(df) <- c()

set.seed(3456)
train_indeks <- createDataPartition(df$CRP, 
                                    p = .8, 
                                    list = FALSE, 
                                    times = 1)

train <- df[train_indeks, ]
test <- df[-train_indeks, ]
train_x <- train %>% dplyr::select(-CRP)
train_y <- train$CRP
test_x <- test %>% dplyr::select(-CRP)
test_y <- test$CRP

#tek bir veri seti 
training <- data.frame(train_x, CRP = train_y)
```

##model
```{r}
knn_fit <- knn.reg(train = train_x, 
                   test = test_x, 
                   y = train_y, 
                   k = 10)

names(knn_fit)

head(knn_fit$pred)
```


##test hatasının hesaplanması
```{r}
defaultSummary(data.frame(obs = test_y, pred = knn_fit$pred))


```

##tahmin 
```{r}

#knn.reg fonk çalıştırıldığında prediction işlemini de yapar ekstra koda gerek yok
knn_fit <- knn.reg(train = train_x, 
                   test = test_x, 
                   y = train_y, 
                   k = 10)

#knn algoritmasının kendisi tahmin hesaplıyor
```

##Test hatasının hesaplanması
```{r}
head(knn_fit$pred)
defaultSummary(data.frame(obs = test_y, 
                          pred = knn_fit$pred))

```
##Model tuning
```{r}

ctrl <- trainControl(method = "cv", number = 10)

knn_grid <- data.frame(k = 1:20)

knn_tune <- train(train_x, train_y,
                  method = "knn",
                  trControl = ctrl,
                  tuneGrid = knn_grid,
                  preProc = c("center", "scale"))


plot(knn_tune)

knn_tune$finalModel
#k=5

```

##Model Test Hatasi
```{r}
defaultSummary(data.frame(obs = test_y,
pred = predict(knn_tune, test_x)))
```
#2. SVR (Support Vector Regression)
```{r}

df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


#df$`Patient_Followup_Status` <- factor(df$`Patient_Followup_Status` , 
#                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
#                                ordered = T
#                                )

df$`Case_Status` <- factor(df$`Case_Status` , 
                                levels = c("Bad","Medium","Good"),
                                ordered = T
                                )
df$`Pregnancy` <- factor(df$`Pregnancy` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`Intensive_care` <- factor(df$`Intensive_care` , 
                                levels = c("Yes" , "No"),
                                ordered =T
                                )
df$`Pneumonia` <- factor(df$`Pneumonia` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`CT` <- factor(df$`CT` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
```

## Model
```{r}
#df<- df%>% dplyr :: select(c("Yas", "CRP", "Ferritin", "Oksijen"))

df <- df %>% dplyr::select(-c("Hospital", "Notification_District", "CT_Result", "Process_Status", "Province", "District", "Neighborhood"))

df$Case_Status <- ifelse(df$Case_Status=="Bad",0,ifelse(df$Case_Status=="Medium",1,2))
df$Sex <- ifelse(df$Sex=="Female",0,1)
df$Patient_Followup_Status <- ifelse(df$Patient_Followup_Status=="Home Isolation/Ambulatory",0,1)
df$Contact <- ifelse(df$Contact=="Yes",0,1)
df$Pregnancy <- ifelse(df$Pregnancy=="Yes",0,1)
df$Intensive_care <- ifelse(df$Intensive_care=="Yes",0,1)
df$Intubation <- ifelse(df$Intubation=="Yes",0,1)
df$CT <- ifelse(df$CT=="Yes",0,1)
df$Pneumonia <- ifelse(df$Pneumonia=="Yes",0,1)

set.seed(3456)
train_indeks <- createDataPartition(df$CRP, 
                                    p = 0.8, 
                                    list = FALSE, 
                                    times = 1)

train <- df[train_indeks, ]
test <- df[-train_indeks, ]
train_x <- train %>% dplyr::select(-CRP)
train_y <- train$CRP
test_x <- test %>% dplyr::select(-CRP)
test_y <- test$CRP

#tek bir veri seti 
training <- data.frame(train_x, CRP = train_y)

df <- scale(train)
df <- scale(test)
df <- scale(train_x)
df <- scale(train_y)
df <- scale(test_x)
df <- scale(test_y)
df <- scale(training)

svm_fit <- svm(train_x, train_y)
names(svm_fit)
```

## Train Test Hata
```{r}
defaultSummary(data.frame(obs = train_y,
pred = predict(svm_fit, train_x)))

defaultSummary(data.frame(obs = test_y,
pred = predict(svm_fit, test_x)))
```


##Model Tunning

c ceza katsayısı tune edilir
```{r}
ctrl <- trainControl(method = "cv", number = 10)

svm_tune <- train(train_x, train_y,
                  method = "svmRadial",
                  trControl = ctrl,
                  tuneLength = 14,
                  preProc = c("center", "scale"))

plot(svm_tune)

svm_tune$finalModel

defaultSummary(data.frame(obs = train_y,
pred = predict(svm_tune, train_x)))

defaultSummary(data.frame(obs = test_y,pred = predict(svm_tune, test_x)))
#RMSE= 1.4152644  , R2= 0.1072534, MAE= 0.7667942 
```

#3. CART
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


#df$`Patient_Followup_Status` <- factor(df$`Patient_Followup_Status` , 
#                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
#                                ordered = T
#                                )

df$`Case_Status` <- factor(df$`Case_Status` , 
                                levels = c("Bad","Medium","Good"),
                                ordered = T
                                )
df$`Pregnancy` <- factor(df$`Pregnancy` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`Intensive_care` <- factor(df$`Intensive_care` , 
                                levels = c("Yes" , "No"),
                                ordered =T
                                )
df$`Pneumonia` <- factor(df$`Pneumonia` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`CT` <- factor(df$`CT` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
```

##Model
```{r}
df <- df %>% dplyr::select(-c("Hospital", "Notification_District", "Process_Status", "Province", "District", "CT", "Neighborhood"))

#df$Case_Status <- ifelse(df$Case_Status=="Bad",0,ifelse(df$Case_Status=="Medium",1,2))
#df$Sex <- ifelse(df$Sex=="Female",0,1)
#df$Patient_Followup_Status <- ifelse(df$Patient_Followup_Status=="Home Isolation/Ambulatory",0,1)
#df$Contact <- ifelse(df$Contact=="Yes",0,1)
#df$Pregnancy <- ifelse(df$Pregnancy=="Yes",0,1)
#df$Intensive_care <- ifelse(df$Intensive_care=="Yes",0,1)
#df$Intubation <- ifelse(df$Intubation=="Yes",0,1)
#df$CT <- ifelse(df$CT=="Yes",0,1)
#df$Pneumonia <- ifelse(df$Pneumonia=="Yes",0,1)

set.seed(3456)
train_indeks <- createDataPartition(df$CRP, 
                                    p = 0.8, 
                                    list = FALSE, 
                                    times = 1)

train <- df[train_indeks, ]
test <- df[-train_indeks, ]
train_x <- train %>% dplyr::select(-CRP)
train_y <- train$CRP
test_x <- test %>% dplyr::select(-CRP)
test_y <- test$CRP

#tek bir veri seti 
training <- data.frame(train_x, CRP = train_y)

cart_tree <- rpart(CRP ~ ., data = train)


#değişkenlerin önemlilik skorları
cart_tree$variable.importance

plot(cart_tree, margin = 0.1)
text(cart_tree, cex = 0.5)
#farklı gösterim
prp(cart_tree, type = 4)
#farklı gösterim
rpart.plot(cart_tree)

#ağacın ne kadar budanması gerektiğini anlamak için
plotcp(cart_tree)

```

##Eksenlerde Gosterim
```{r}

train %>% mutate(y_sapka = predict(cart_tree)) %>%
  ggplot() +
  geom_point(aes(Oxygen, CRP)) +
  geom_step(aes(Oxygen, y_sapka), col = "red")


```

##Karmasiklik Parametresi ve minsplitit 
```{r}
#minsplit ağacın dallanma sonucu oluşan en son yapraklarında olacak gözlem sayısı, cp=complexity
#genellenebilirlik kaygısı olmadan mevcut yapıyı tanımlamak için en uygun fonk CART
cart_tree2 <- rpart(CRP ~ ., data = train,
                   control = rpart.control(cp = 0, 
                                           minsplit = 2))


train %>% mutate(y_sapka = predict(cart_tree2)) %>%
  ggplot() +
  geom_point(aes(Oxygen, CRP)) +
  geom_step(aes(Oxygen, y_sapka), col = "red")

cart_tree2$variable.importance

cart_tree3 <- rpart(CRP ~ ., data = train,
                   control = rpart.control(cp = 0.06, 
                                           minsplit = 3))


train %>% mutate(y_sapka = predict(cart_tree3)) %>%
  ggplot() +
  geom_point(aes(Oxygen, CRP)) +
  geom_step(aes(Oxygen, y_sapka), col = "red")

cart_tree3$variable.importance

```
##Agacin Budanmasi
```{r}
#dalların ne kadar derinliğine inmesi gerektiği

prune_cart <- prune(cart_tree, cp = 0.01)


train %>% mutate(y_sapka = predict(prune_cart)) %>%
  ggplot() +
  geom_point(aes(Oxygen, CRP)) +
  geom_step(aes(Oxygen, y_sapka), col = "red")

plot(prune_cart, margin = 0.01)
text(prune_cart, cex = 0.5)
rpart.plot(prune_cart,cex = 0.8)

```

##tahmin
```{r}

head(predict(prune_cart))

defaultSummary(data.frame(obs = train_y, pred = predict(prune_cart, train_x)))

defaultSummary(data.frame(obs = test_y, pred = predict(prune_cart, test_x)))

```



##Model tuning
```{r}
ctrl <- trainControl(method = "cv", number = 10)

tune_grid <- data.frame(
  cp = seq(0, 0.05, len = 25)
  
)

#train fonk içerisinde model rpart yazılırsa cp değerini, rpart2 yaptığında maksimum derinlik parametresini optimize edilir. metoda ne yazarsak onun için tune grid argümanı kullanılır.

cart_tune <- train(CRP~.,
                  method = "rpart",
                  trControl = ctrl,
                  tuneGrid = tune_grid,
                  preProc = c("center", "scale"), data = df)

cart_tune

plot(cart_tune)

cart_tune$bestTune
cart_tune$finalModel

plot(cart_tune$finalModel)
text(cart_tune)
rpart.plot(cart_tune$finalModel,cex = 0.8)

plot(predict(cart_tune), df$CRP, xlab = "Predict",ylab = "Real")
abline(0,1)


plot(as.party(cart_tree))


defaultSummary(data.frame(obs = train_y, pred = predict(cart_tune, train_x)))

#defaultSummary(data.frame(obs = df$CRP,pred = predict(cart_tune)))

defaultSummary(data.frame(obs = test_y, pred = predict(cart_tune, test_x)))


```


#4. Bagged Trees
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


#df$`Patient_Followup_Status` <- factor(df$`Patient_Followup_Status` , 
#                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
#                                ordered = T
#                                )

df$`Case_Status` <- factor(df$`Case_Status` , 
                                levels = c("Bad","Medium","Good"),
                                ordered = T
                                )
df$`Pregnancy` <- factor(df$`Pregnancy` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`Intensive_care` <- factor(df$`Intensive_care` , 
                                levels = c("Yes" , "No"),
                                ordered =T
                                )
df$`Pneumonia` <- factor(df$`Pneumonia` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`CT` <- factor(df$`CT` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
```

## Model

```{r}
df <- df %>% dplyr::select(-c("Hospital", "Notification_District",  "Province", "District", "Neighborhood"))

set.seed(3456)
train_indeks <- createDataPartition(df$CRP, 
                                  p = .8, 
                                  list = FALSE, 
                                  times = 1)


train <- df[train_indeks,]
test  <- df[-train_indeks,]


train_x <- train %>% dplyr::select(-CRP)
train_y <- train$CRP
test_x <- test %>% dplyr::select(-CRP)
test_y <- test$CRP


#tek bir veri seti
training <- data.frame(train_x, CRP = train_y)

#bagging reg kurmanın 3 tane farklı yolu vardır

#birinci yöntem
bag_fit1 <- ipredbagg(train_y, train_x)
bag_fit1


defaultSummary(data.frame(obs = train_y,
pred = predict(bag_fit1, train_x)))

defaultSummary(data.frame(obs = test_y,
pred = predict(bag_fit1, test_x)))



#ikinci yöntem
bag_fit2 <- bagging(CRP~ ., data = training)

#bag_fit2


defaultSummary(data.frame(obs = train_y,
pred = predict(bag_fit2, train_x)))

defaultSummary(data.frame(obs = test_y,
pred = predict(bag_fit2, test_x)))


#üçüncü yöntem
bag_fit3 <- randomForest(training$CRP ~ . , data = training,
             mtry = ncol(training) - 1,
             importance = TRUE,
             ntrees = 2000
             )

bag_fit3
summary(training$CRP)

#değişkenlerin önem düzeyleri
importance(bag_fit3)
varImpPlot(bag_fit3)
```

## Tahmin train test hatası
```{r}

predict(bag_fit3, test_x)

defaultSummary(data.frame(obs = train_y,
pred = predict(bag_fit3, train_x)))

defaultSummary(data.frame(obs = test_y,
pred = predict(bag_fit3, test_x)))


plot(bag_fit3, col = "dodgerblue", 
     lwd = 2, 
     main = "Bagged Trees: Comparison of Error and Number of Tree")
grid()



```

## Model Tuning

```{r}

ctrl <- trainControl(method = "cv", number = 10)

mtry <- ncol(train_x)
tune_grid <- expand.grid(mtry = mtry)


bag_tune <- train(train_x, train_y, 
                  method = "rf", 
                  tuneGrid = tune_grid,
                  trControl = ctrl)




defaultSummary(data.frame(obs = train_y,
pred = predict(bag_tune, train_x)))

defaultSummary(data.frame(obs = test_y,
pred = predict(bag_tune, test_x)))


```

#5. Random Forest
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


#df$`Patient_Followup_Status` <- factor(df$`Patient_Followup_Status` , 
#                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
#                                ordered = T
#                                )

df$`Case_Status` <- factor(df$`Case_Status` , 
                                levels = c("Bad","Medium","Good"),
                                ordered = T
                                )
df$`Pregnancy` <- factor(df$`Pregnancy` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`Intensive_care` <- factor(df$`Intensive_care` , 
                                levels = c("Yes" , "No"),
                                ordered =T
                                )
df$`Pneumonia` <- factor(df$`Pneumonia` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`CT` <- factor(df$`CT` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
```

##model 
```{r}

df <- df %>% dplyr::select(-c("Hospital", "Notification_District",  "Province", "District", "Neighborhood"))

set.seed(3456)
train_indeks <- createDataPartition(df$CRP, 
                                  p = .8, 
                                  list = FALSE, 
                                  times = 1)


train <- df[train_indeks,]
test  <- df[-train_indeks,]


train_x <- train %>% dplyr::select(-CRP)
train_y <- train$CRP
test_x <- test %>% dplyr::select(-CRP)
test_y <- test$CRP

training <- data.frame(train_x, CRP = train_y)

rf_fit <- randomForest(train_x, train_y,importance = TRUE)

importance(rf_fit)
varImpPlot(rf_fit)


rf_fit
```
##tahmin

```{r}

predict(rf_fit, test_x )

plot(predict(rf_fit, test_x), test_y,
     xlab = "Tahmin Edilen", ylab = "Gercek",
     main = "Tahmin Edilen vs Gercek: Random Forest",
     col = "dodgerblue", pch = 20)
#outline
grid()
abline(0, 1, col = "darkorange", lwd = 2) 

defaultSummary(data.frame(obs = train_y,
pred = predict(rf_fit, train_x)))
#test hatası
defaultSummary(data.frame(obs = test_y,
pred = predict(rf_fit, test_x)))

```
##model tunning

mtry(rastgele değişken sayısı: reg problemlerinde değişken sayısı/3; sınıflandırma problemlerinde değ sayısının karekökü) ve ntree(boostrap örneklem sayısı) seçilmesi gerekir. 

```{r}

ctrl <- trainControl(method = "cv", number = 10)

#mtry(rastgele değişken sayısı: reg problemlerinde değişken sayısı/3; sınıflandırma problemlerinde değ sayısının karekökü) ve ntree(boostrap örneklem sayısı) seçilmesi gerekir. 

ncol(train_x)/3

tune_grid <- expand.grid(mtry = c(2,3,4,5,10))
rf_tune <- train( train_x, train_y,
                  method = "rf",
                  tuneGrid = tune_grid,
                  trControl = ctrl

)

#opt değişken sayısı mtry = 5
rf_tune
plot(rf_tune)

#opt parametre ile oluşmuş olan değerler
rf_tune$results %>% filter(mtry == as.numeric(rf_tune$bestTune))


#opt parametre ile test hatası
defaultSummary(data.frame(obs = test_y, 
                            pred = predict(rf_tune, test_x)))

```
##caret ile random search

arama türü grid ya da random olarak yapılabilir
```{r}
#search grid değil random yapılır
ctrl <- trainControl(method = "cv", 
                     number = 10,
                     search = "random")

#tunedrid yerine tunelength (kaç kere maks deneme yapılacağı)
rf_random_tune <- train( train_x, train_y,
                  method = "rf",
                  tuneLength = 5,
                  trControl = ctrl

)

rf_random_tune



```



##caret ile grid search
```{r}

ctrl <- trainControl(method = "cv", 
                     number = 10,
                     search = "grid")

tune_grid <- expand.grid(mtry = c(1:10))

rf_random_tune <- train(train_x, train_y,
                  method = "rf",
                  tuneGrid = tune_grid,
                  trControl = ctrl

)



model_listesi <- list()

for (ntree in c(100, 200, 300, 500, 1000, 2000)) {
  
  set.seed(123)
  
  fit <- train(train_x, train_y,
                  method = "rf",
                  tuneGrid = tune_grid,
                  trControl = ctrl, 
                  ntree = ntree)

  key <- toString(ntree)
  model_listesi[[key]] <- fit
  
}

sonuclar <- resamples(model_listesi)
summary(sonuclar)

rf_tuned <- randomForest(train_x, train_y,mtry=3,ntree=300,importance = TRUE)



defaultSummary(data.frame(obs = train_y, 
                            pred = predict(rf_tuned, train_x)))


defaultSummary(data.frame(obs = test_y, 
                            pred = predict(rf_tuned, test_x)))
```

#6. GBM
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


#df$`Patient_Followup_Status` <- factor(df$`Patient_Followup_Status` , 
#                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
#                                ordered = T
#                                )

df$`Case_Status` <- factor(df$`Case_Status` , 
                                levels = c("Bad","Medium","Good"),
                                ordered = T
                                )
df$`Pregnancy` <- factor(df$`Pregnancy` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`Intensive_care` <- factor(df$`Intensive_care` , 
                                levels = c("Yes" , "No"),
                                ordered =T
                                )
df$`Pneumonia` <- factor(df$`Pneumonia` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`CT` <- factor(df$`CT` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
```

## Model
```{r}


df <- df %>% dplyr::select(-c("Hospital", "Notification_District",  "Province", "District", "Neighborhood"))
gbm_fit <- gbm(CRP ~ ., data = training ,
    distribution = "gaussian", 
    n.trees = 5000, #ağaç sayısı
    interaction.depth = 1,  #derinlik
    shrinkage = 0.01, #learning rate
    cv.folds = 5)

summary(gbm_fit) #değişkenlerin önem düzeyleri ve görselleri

#names(gbm_fit)

gbm.perf(gbm_fit, method = "cv") #İterasyon(ağaç) sayısı arttıkça hata durumu görseli

?gbm

```
##Train hata
```{r}
defaultSummary(data.frame(obs = train_y, 
                            pred = gbm_fit$fit))

```

## Tahmin


```{r}

predict(gbm_fit, test_x, n.trees = 5000)


defaultSummary(data.frame(obs = test_y, 
                            pred = predict(gbm_fit, test_x, n.trees = 5000)))


plot(predict(gbm_fit, test_x, n.trees = 5000), test_y,
     xlab = "Tahmin Edilen", ylab = "Gercek",
     main = "Tahmin Edilen vs Gercek: GBM",
     col = "dodgerblue", pch = 20)

grid()

abline(0, 1, col = "darkorange", lwd = 2)

```


## Model Tuning
Optimize edilecek parametreler
ntrees
interaction debt(karmaşıklık/derinlik katsayısı)
shrinkage(öğrenme/adabte olma hızı)
min gözlem sayısı

```{r}
ctrl <- trainControl(method = "cv", 10,
                     search = "grid")


gbm_grid <- expand.grid(
            interaction.depth = seq(1, 7, by = 2),
            n.trees = seq(0, 6000, by = 500),
            shrinkage = c(0.01, 0.1),
            n.minobsinnode = c(10:20))

#seq(1000, 6000, by = 200)
gbm_tune_fit <- train(train_x, train_y, 
      method = "gbm",
      trControl = ctrl,
      tuneGrid = gbm_grid,
      verbose = FALSE
      )

?gbm
plot(gbm_tune_fit)
gbm_tune_fit$finalModel

gbm_tune_fit$results %>% 
  filter(n.trees == as.numeric(gbm_tune_fit$bestTune$n.trees) &
         interaction.depth == as.numeric(gbm_tune_fit$bestTune$interaction.depth) &
         shrinkage == as.numeric(gbm_tune_fit$bestTune$shrinkage) &
        n.minobsinnode == as.numeric(gbm_tune_fit$bestTune$n.minobsinnode))

defaultSummary(data.frame(obs = train_y, 
                            pred = predict(gbm_tune_fit, train_x)))

defaultSummary(data.frame(obs = test_y, 
                            pred = predict(gbm_tune_fit, test_x)))

```

#7. XGBoost 
```{r}
df<-Veri_normal_oksijenli2
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hastane_Adi","Cinsiyet","Hasta_Takip_Durumu", "Vaka_Durumu","Temaslı_mi","Gebe_Mi","Bildirim_İlcesi","Yogun_Bakimda_Mi","Entübasyon_Var_mi","Yas","BT_Sonucu","BT","Pnomoni", "Sürec_Durumu", "Mernis_il","Mernis_ilce","Mernis_mahalle","Ferritin","CRP","Oksijen")
#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Gebe_Mi`))
df$`Gebe_Mi`[indeks_eksikgebelik] <- "Hayır"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`BT_Sonucu`))
df$`BT_Sonucu`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


df$`Hasta_Takip_Durumu` <- factor(df$`Hasta_Takip_Durumu` , 
                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
                                ordered = T
                                )

df$`Vaka_Durumu` <- factor(df$`Vaka_Durumu` , 
                                levels = c("Kötü","Orta","İyi"),
                                ordered = T
                                )
df$`Gebe_Mi` <- factor(df$`Gebe_Mi` , 
                                levels = c("Evet" , "Hayır"),
                                ordered = T
                                )
df$`Yogun_Bakimda_Mi` <- factor(df$`Yogun_Bakimda_Mi` , 
                                levels = c("Evet" , "Hayır"),
                                ordered =T
                                )
df$`Pnomoni` <- factor(df$`Pnomoni` , 
                                levels = c("VAR" , "YOK"),
                                ordered = T
                                )
df$`BT` <- factor(df$`BT` , 
                                levels = c("VAR" , "YOK"),
                                ordered = T
                                )
```

```{r}
df<-df %>% dplyr::select(c("Yas","Oksijen","Ferritin","CRP"))

set.seed(3456)
train_indeks <- createDataPartition(df$CRP, 
                                  p = .8, 
                                  list = FALSE, 
                                  times = 1)


train <- df[train_indeks,]
test  <- df[-train_indeks,]


train_x <- train %>% dplyr::select(-CRP)
train_y <- train$CRP
test_x <- test %>% dplyr::select(-CRP)
test_y <- test$CRP

training <- data.frame(train_x, CRP = train_y)
```

## Model 

Model
```{r}

xgboost_fit <-xgboost(data = as.matrix(train_x),
        label = train_y, 
        booster = "gblinear",
        max.depth = 2,#ağaç derinliiği
        eta = 1,#learning rate
        nthread = 2, #paralel olarak çalıştırılacak işlemci sayısı
        nrounds = 1000)#verinin üzerinden geçme sayısı, iterasyon sayısı

#xgboostun kendi veri tipine dönüşüm
dtrain <- xgb.DMatrix(data = as.matrix(train_x), label = train_y)
dtest <- xgb.DMatrix(data = as.matrix(test_x), label = test_y)

xgboost_fit <-xgboost(data = dtrain, 
        booster = "gblinear",
        max.depth = 2,
        eta = 1,
        nthread = 2, 
        nrounds = 1000)


#değişken önem düzeyleri
imp_matris <- xgb.importance(model = xgboost_fit)
imp_matris

xgb.plot.importance(imp_matris)

```
Model Takip: watchlist
```{r}

watchlist <- list(train = dtrain, test = dtest)

xgb_fit <- xgb.train(data = dtrain, 
                     booster = "gblinear",
                     max.depth = 2,
                     eta = 1, 
                     nthread = 2,
                     nrounds = 100,
                     watchlist = watchlist)

```


## Tahmin

```{r}
predict(xgb_fit, as.matrix(test_x))

plot(predict(xgb_fit, as.matrix(test_x)), test_y,
     xlab = "Tahmin Edilen", ylab = "Gercek",
     main = "Tahmin Edilen vs Gercek: XGBoost",
     col = "dodgerblue", pch = 20)
grid()
abline(0, 1, col = "darkorange", lwd = 2)

defaultSummary(data.frame(obs = train_y, 
                            pred = predict(xgb_fit, as.matrix(train_x))))

defaultSummary(data.frame(obs = test_y, 
                            pred = predict(xgb_fit, as.matrix(test_x))))

```

## Model Tuning
```{r}


ctrl <- trainControl(method = "cv", number = 10)

xgb_grid <- expand.grid(
  nrounds = 1000,
  lambda = c(1,2,3),
  alpha = c(0, 0.5, 1),
  eta = c(0, 0.5, 1) #daraltma adım boyu
)


xgb_tune_fit <- train(
  x = data.matrix(train_x),
  y = train_y,
  trControl = ctrl,
  tuneGrid = xgb_grid,
  method = "xgbLinear"
)

defaultSummary(data.frame(obs = train_y, 
                            pred = predict(xgb_tune_fit, as.matrix(train_x))))

defaultSummary(data.frame(obs = test_y, 
                            pred = predict(xgb_tune_fit, as.matrix(test_x))))

```

# Gelismis Hiperparametre Optimizasyonu
Bu bolum bir kac kaggle kerneli ve buraya kdarki tum deneyimlerimiz ile derlendi.

https://www.kaggle.com/pelkoja/visual-xgboost-tuning-with-caret


## Default Hiperparametreler

carette tune edilebilir parametreler
nrounds: 1000 
max_depth: 6 (ağaçların derinlik katsayısı )
eta: 0.3    (öğrenme katsayısı -/oranı yüksek olması grid searchu hızlı yapar ama doğruluğu düşürür)
gamma: 0     (ağacın yaprağının dallanmasını jontrol etmek için)
colsample_bytree: 1 (oluşturulacak her ağaçta değişkenlerden alınacak örneklem sayısı)
min_child_weight:1  (bölünme kontrolü ile ilgili=
subsample 1: (eğitimde kullanılacak gözlem değeri 1 ise tüm değerler bu parametre 0.5 olması 1 olmasına göre overfittingi engellemeyi sağlar)




```{r}

grid_default <- expand.grid(
  nrounds = 100,
  max_depth = 6,
  eta = 0.3,
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1
)

ctrl <- trainControl(
  method = "none",
  verboseIter = FALSE,
  allowParallel = TRUE
  
)

xgb_base <- train(
  x = as.matrix(train_x),
  y = train_y,
  trControl = ctrl,
  tuneGrid = grid_default,
  method = "xgbTree",
  verbose = TRUE
  
)
xgb_base$bestTune
# nrounds
#<100>
#max_depth
#<6>
#eta
#<0.3>
#gamma
#<0>
#colsample_bytree
#<1>
#min_child_weight
#<1>
#subsample
#<1>

defaultSummary(data.frame(obs = test_y, 
                            pred = predict(xgb_base, as.matrix(test_x))))
# RMSE  Rsquared       MAE 
#1.7655817 0.1232671 0.9050823 
```
## Adim 1: Iterasyon Sayisi ve Learning Rate Belirlenmesi
```{r}

nrounds <- 1000

tune_grid <- expand.grid(
  nrounds = seq(from = 100, to = nrounds, by = 50), 
  eta = c(0.025, 0.05, 0.1, 0.3, 0.4),
  max_depth = c(2, 3, 4, 5, 6, 7, 8),
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1
)

ctrl <- trainControl(
  method = "cv", 
  number = 10, 
  verboseIter = FALSE, 
  allowParallel = TRUE  
)


xgb_tune <- train(
  x = as.matrix(train_x),
  y = train_y,
  trControl = ctrl,
  tuneGrid = tune_grid,
  method = "xgbTree",
  verbose = TRUE
)
#The final values used for the model were nrounds = 250, max_depth = 2, eta = 0.025, gamma = 0, colsample_bytree = 1, min_child_weight = 1 and subsample = 1.

defaultSummary(data.frame(obs = test_y, 
                            pred = predict(xgb_tune, as.matrix(test_x))))

# RMSE  Rsquared       MAE 
#1.3041399 0.1802945  0.7660420  

tuneplot <- function(x, probs = .90) {
  ggplot(x) +
  coord_cartesian(ylim = c(quantile(x$results$RMSE, probs = probs), min(x$results$RMSE))) +
    theme_bw()
}


tuneplot(xgb_tune)

xgb_tune$bestTune

# nrounds
#<200>
#max_depth
#<2>
#eta
#<0.025>
#gamma
#<0>
#colsample_bytree
#<1>
#min_child_weight
#<1>
#subsample
#<1>





```
## Adim 2: Maksimum Derinlik ve Minimum Child Weight
```{r}

tune_grid2 <- expand.grid(
  nrounds = seq(from = 50, to = nrounds, by = 50),
  eta = xgb_tune$bestTune$eta,
  max_depth = c(2, 3, 4),
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = c(1, 2, 3),
  subsample = 1
)


xgb_tune2 <- train(
  x = as.matrix(train_x),
  y = train_y,
  trControl = ctrl,
  tuneGrid = tune_grid2,
  method = "xgbTree",
  verbose = TRUE
)


#The final values used for the model were nrounds 0, colsample_bytree = 1, min_child_weight = 1 and subsample = 1.
tuneplot(xgb_tune2)

xgb_tune2$bestTune

#nrounds
#100
#max_depth
#2
#eta
#0.025
#gamma
#0
#colsample_bytree
#1
#min_child_weight
#3
#subsample
#1

defaultSummary(data.frame(obs = test_y, 
                            pred = predict(xgb_tune2, as.matrix(test_x))))

# RMSE  Rsquared       MAE 
#1.2364345  0.1757638 0.7487534  

```

##Adim 3: Degisken ve Gozlem Orneklemesi
```{r}

tune_grid3 <- expand.grid(
  nrounds = seq(from = 50, to = nrounds, by = 50),
  eta = xgb_tune$bestTune$eta,
  max_depth = 2, 
  gamma = 0,
  colsample_bytree = c(0.4, 0.6, 0.8, 1.0), 
  min_child_weight = xgb_tune2$bestTune$min_child_weight,
  subsample = c(0.5, 0.75, 1.0) 
)

xgb_tune3 <- train(
  x = as.matrix(train_x),
  y = train_y,
  trControl = ctrl,
  tuneGrid = tune_grid3,
  method = "xgbTree",
  verbose = TRUE
)


tuneplot(xgb_tune3)

xgb_tune3$bestTune

#nrounds
#100
#max_depth
#2
#eta
#0.025
#gamma
#0
#colsample_bytree
#1
#min_child_weight
#3
#subsample
#0.75

defaultSummary(data.frame(obs = test_y, 
                            pred = predict(xgb_tune3, as.matrix(test_x))))

#RMSE  Rsquared       MAE 
#1.2319669 0.1968613 0.7472391 
```

## Adim 4: Gamma ağacın lif nodu(dallanma) kontrolü için
```{r}
tune_grid4 <- expand.grid(
  nrounds = seq(from = 50, to = nrounds, by = 50),
  eta = xgb_tune$bestTune$eta,
  max_depth = 2,
  gamma = c(0, 0.05, 0.1, 0.5, 0.7, 0.9, 1.0),
  colsample_bytree = xgb_tune3$bestTune$colsample_bytree,
  min_child_weight = xgb_tune2$bestTune$min_child_weight,
  subsample = xgb_tune3$bestTune$subsample
)

xgb_tune4 <- train(
  x = as.matrix(train_x),
  y = train_y,
  trControl = ctrl,
  tuneGrid = tune_grid4,
  method = "xgbTree",
  verbose = TRUE
)

tuneplot(xgb_tune4)
xgb_tune4$bestTune
#nrounds
#300
#max_depth
#5
#eta
#0.025
#gamma
#1
#colsample_bytree
#1
#min_child_weight
#3
#subsample
#0.75

defaultSummary(data.frame(obs = test_y, 
                            pred = predict(xgb_tune4, as.matrix(test_x))))

#RMSE  Rsquared       MAE 
#1.3842777 0.1896809 0.7834528
```
##Adim 5: Learning Rate'in Indirgenmesi
```{r}


tune_grid5 <- expand.grid(
  nrounds = seq(from = 100, to = 1000, by = 50),
  eta = c(0.01, 0.015, 0.025, 0.05, 0.1),
  max_depth = xgb_tune2$bestTune$max_depth,
  gamma = xgb_tune4$bestTune$gamma,
  colsample_bytree = xgb_tune3$bestTune$colsample_bytree,
  min_child_weight = xgb_tune2$bestTune$min_child_weight,
  subsample = xgb_tune3$bestTune$subsample
)

xgb_tune5 <- train(
  x = as.matrix(train_x),
  y = train_y,
  trControl = ctrl,
  tuneGrid = tune_grid5,
  method = "xgbTree",
  verbose = TRUE
)

tuneplot(xgb_tune5)

xgb_tune5$bestTune
#nrounds
#150
#max_depth
#2
#eta
#0.025
#gamma
#1
#colsample_bytree
#1
#min_child_weight
#3
#subsample
#0.75
defaultSummary(data.frame(obs = test_y, 
                            pred = predict(xgb_tune5, test_x)))
# RMSE  Rsquared       MAE 
#1.2994713 0.1928334 0.7653132 
```
## Adim 6: Son Model
```{r}

final_grid <- expand.grid(
  nrounds = xgb_tune5$bestTune$nrounds,
  eta = xgb_tune5$bestTune$eta,
  max_depth = xgb_tune5$bestTune$max_depth,
  gamma = xgb_tune5$bestTune$gamma,
  colsample_bytree = xgb_tune5$bestTune$colsample_bytree,
  min_child_weight = xgb_tune5$bestTune$min_child_weight,
  subsample = xgb_tune5$bestTune$subsample
)


xgb_son_model <- train(
  x = as.matrix(train_x),
  y = train_y,
  trControl = ctrl,
  tuneGrid = final_grid,
  method = "xgbTree",
  verbose = TRUE
)


#test hatasi
defaultSummary(data.frame(obs = test_y, 
                            pred = predict(xgb_son_model, as.matrix(test_x))))


#     RMSE  Rsquared       MAE 
#1.2900708 0.1931077 0.7638875 
xgb_son_model$bestTune

#nrounds
#150
#max_depth
#2
#eta
#0.025
#gamma
#1
#colsample_bytree
#1
#min_child_weight
#3
#subsample
#0.75
```

## Adim 7: Model Kaydetmek ve Paylasmak

Model Nesnesinin Kaydedilmesi
```{r}

save(xgb_son_model, file = "xgb_son_model.rda")
rm(xgb_son_model)
load("xgb_son_model.rda")

predict(xgb_son_model, test_x)

```

#SINIFLANDIRMA

#1. Multinomial Logistic Regression
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)


#df$`Patient_Followup_Status` <- factor(df$`Patient_Followup_Status` , 
#                                levels = c("Hastanede" , "Evde İzolasyon/Ayaktan"),
#                                ordered = T
#                                )

df$`Case_Status` <- factor(df$`Case_Status` , 
                                levels = c("Bad","Medium","Good"),
                                ordered = T
                                )
df$`Pregnancy` <- factor(df$`Pregnancy` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`Intensive_care` <- factor(df$`Intensive_care` , 
                                levels = c("Yes" , "No"),
                                ordered =T
                                )
df$`Pneumonia` <- factor(df$`Pneumonia` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
df$`CT` <- factor(df$`CT` , 
                                levels = c("Yes" , "No"),
                                ordered = T
                                )
```

##Train ve Test Ayrımı 

```{r}
df<- df %>% dplyr::select(-c("Hospital","Notification_District","Province","District","Neighborhood"))

#trainTestSplit <- function(data , dvName , seed){
  
 #         tbl <- table(data[,dvName])
 #         classes <- names(tbl)
 #         minClass <- min(tbl)
 #         lengthClass <- length(tbl)
          
 #         train <- data.frame()
 #         test <- data.frame()
          
 #         for(i in 1:lengthClass){
              
  #           selectedClass <- data[,dvName] == classes[i]
 #            set.seed(seed)
  #           sampleIndex <- sample(1:nrow(data[selectedClass , ]) , size = minClass*0.8)
             
  #           train <- rbind(train , data[selectedClass , ][sampleIndex , ])
  #           test <- rbind(test , data[selectedClass , ][-sampleIndex , ])
  #        }
          
  #        return(list(train , test))
  
#}

#train <- trainTestSplit(df , "Case_Status" , 125)[[1]]
#test <- trainTestSplit(df , "Case_Status" , 125)[[2]]

#table(train$Case_Status)
#table(test$Case_Status)


set.seed(123)
train_indeks <- createDataPartition(df$Case_Status, 
                                  p = .8, 
                                  list = FALSE, 
                                  times = 1)


train <- df[train_indeks,]
test  <- df[-train_indeks,]


train_x <- train %>% dplyr::select(-Case_Status)
train_y <- train$Case_Status
test_x <- test %>% dplyr::select(-Case_Status)
test_y <- test$Case_Status


#tek bir veri seti
training <- data.frame(train_x, Case_Status = train_y)
```



##Keşfecidici Veri Analizi
```{r}
par(mfrow= c(2,2))
plot(train$Case_Status , train$Age , main = "Age")
plot(train$Case_Status , train$Ferritin , main = "Ferritin")
plot(train$Case_Status , train$CRP , main = "CRP")
plot(train$Case_Status , train$Oxygen , main = "Oxygen")


## Cinsiyet (bağımsız)
chisq.test(table(train$Case_Status , train$Sex))
table(train$Case_Status , train$Sex)

## Hasta_Takip_Durumu (bağımlı)
chisq.test(table(train$Case_Status , train$Patient_Followup_Status))
table(train$Case_Status , train$Patient_Followup_Status)

## Temaslı_mi (bağımsız)
chisq.test(table(train$Case_Status , train$Contact))
table(train$Case_Status , train$Contact)

# Gebe_Mi (bağımsız)
chisq.test(table(train$Case_Status , train$Pregnancy))
table(train$Case_Status , train$Pregnancy)

# Yogun_Bakimda_Mi(bağımlı)
chisq.test(table(train$Case_Status , train$Intensive_care))
table(train$Case_Status , train$Intensive_care)

# Entübasyon_Var_mi(bağımlı)
chisq.test(table(train$Case_Status , train$Intubation))
table(train$Case_Status , train$Intubation)

## BT_Sonucu (NA)
chisq.test(table(train$Case_Status , train$CT_Result))
table(train$Case_Status , train$CT_Result)

# BT (bağımsız)
chisq.test(table(train$Case_Status , train$CT))
table(train$Case_Status , train$CT)

# Pnomoni(bağımsız)
chisq.test(table(train$Case_Status , train$Pneumonia))
table(train$Case_Status , train$Pneumonia)

# Sürec_Durumu(NA)
chisq.test(table(train$Case_Status , train$Process_Status))
table(train$Case_Status , train$Process_Status)


#Chi-squared approximation may be incorrect, p-value = NA ise bu kat. sayıların frekans değerleri azsa bu hata alınabilir. Sınırda, etkili olabilen değişkenlerdir.


```


##Model
```{r}
# Model Base

modelBase <- multinom(Case_Status ~ . , data = train)

#modelBase$fitted.values
#modelBase$decay

### Farklı Model Karşılaştırmaları

# Model 2 (Ferritinsiz)
model2 <-  multinom(Case_Status ~  Age + CRP + Oxygen + Sex + Patient_Followup_Status + Contact + Pregnancy +Intensive_care + Intensive_care + Intubation + CT_Result + CT + Pneumonia + Process_Status  , data = train)

# Model 3
model3 <- multinom(Case_Status ~ Age + CRP + Oxygen + Patient_Followup_Status + Intensive_care + Intubation  , data = train)

#Model 4
model4 <- multinom(Case_Status ~ Age + CRP + Oxygen + Patient_Followup_Status + Intensive_care + Intubation + CT_Result + Process_Status  , data = train)


summary(modelBase)
summary(model2)
summary(model3)
summary(model4)
```
## Modeller Üzerinden Tahminler 

```{r}
#değişken önem düzeyleri en yüksek olan en önemlidir.
caret::varImp(modelBase)

predModelBase_train <- predict(modelBase , train)
predModelBase_train

predModel2_train <- predict(model2 , train)
predModel2_train


predModel3_train <- predict(model3 , train)
predModel3_train

predModel4_train <- predict(model4 , train)
predModel4_train


caret::confusionMatrix(predModelBase_train , train$Case_Status , mode = "prec_recall", positive="Bad")
caret::confusionMatrix(predModel2_train , train$Case_Status , mode = "prec_recall", positive="Bad")
caret::confusionMatrix(predModel3_train , train$Case_Status , mode = "prec_recall", positive="Bad")
caret::confusionMatrix(predModel4_train , train$Case_Status , mode = "prec_recall", positive="Bad")

caret::varImp(modelBase)

predModelBase <- predict(modelBase , test)
predModelBase

predModel2 <- predict(model2 , test)
predModel2


predModel3 <- predict(model3 , test)
predModel3

predModel4 <- predict(model4 , test)
predModel4

caret::confusionMatrix(predModelBase , test$Case_Status , mode = "prec_recall", positive="Bad")
caret::confusionMatrix(predModel2 , test$Case_Status , mode = "prec_recall", positive="Bad")
caret::confusionMatrix(predModel3 , test$Case_Status , mode = "prec_recall", positive="Bad")
caret::confusionMatrix(predModel4 , test$Case_Status , mode = "prec_recall", positive="Bad")


#Precision: Tahmin ettiklerinin ne kadarı doğru?
#Recall: x sınıfındakilerin ne kadarını doğru tahmin ettin?
```

##Oran Eşitlemeleri 

```{r}

View(test)


table(test$Vaka_Durumu)

testOranlarEsit <- data.frame()

class(test$Vaka_Durumu)

test[test$Vaka_Durumu == "Orta" , ]

sampleIndex_0 <- sample(1:nrow(test[test$Vaka_Durumu == "Orta" , ]) , size = 6)
sampleIndex_2 <- sample(1:nrow(test[test$Vaka_Durumu == "İyi" , ]) , size = 6)

testOranlarEsit <- rbind(testOranlarEsit , test[test$Vaka_Durumu == "Orta" , ][sampleIndex_0 ,])
testOranlarEsit <- rbind(testOranlarEsit , test[test$Vaka_Durumu == "İyi" , ][sampleIndex_2 ,])
testOranlarEsit <- rbind(testOranlarEsit , test[test$Vaka_Durumu == "Kötü" ,])

View(testOranlarEsit)
table(testOranlarEsit$Vaka_Durumu)


predModelBaseOR <- predict(modelBase , testOranlarEsit)
predModelBaseOR

predModel2OR <- predict(model2 , testOranlarEsit)
predModel2OR


predModel3OR <- predict(model3 , testOranlarEsit)
predModel3OR

predModel4OR <- predict(model4 , testOranlarEsit)
predModel4OR

caret::confusionMatrix(predModelBaseOR , testOranlarEsit$Vaka_Durumu , mode = "prec_recall")
caret::confusionMatrix(predModel2OR , testOranlarEsit$Vaka_Durumu , mode = "prec_recall")
caret::confusionMatrix(predModel3OR , testOranlarEsit$Vaka_Durumu , mode = "prec_recall")
caret::confusionMatrix(predModel4OR , testOranlarEsit$Vaka_Durumu , mode = "prec_recall")


```
##Model Tuning 

```{r}
# Decay parametresi: çürüme anlamına gelir. lambda gibi modeldeki katsayılarla oynar. Multinomial reg. noral network üzerinden uygulanıyor, o yüzden decay kullanılır.

modelTuning <- train( Case_Status ~  .  , 
                      data = train,
                      method = "multinom",
                      trControl = trainControl(method = "cv" , number = 5)
                      )

#Yas + CRP + Oksijen + Hasta_Takip_Durumu +  Yogun_Bakimda_Mi +  Entübasyon_Var_mi

#decay = 0

modelTuning$bestTune
modelTuning$finalModel


plot(modelTuning)

modelTuned <- multinom(Case_Status ~ . , 
                       data  = train ,
                       decay = 0.0001	
                      )


predModelTuned <- predict(modelTuned , test)

caret::confusionMatrix(predModelTuned , test$Case_Status , mode = "prec_recall")


# Model 2 için tuning

modelTuning2 <- train( Vaka_Durumu ~ Yas + CRP + Oksijen + Cinsiyet + Hasta_Takip_Durumu + Temaslı_mi + Gebe_Mi +Yogun_Bakimda_Mi + Entübasyon_Var_mi + BT_Sonucu + BT + Pnomoni + Sürec_Durumu   , 
                      data = train,
                      method = "multinom",
                      trControl = trainControl(method = "cv" , number = 5)
)


plot(modelTuning2)

modelTuning2$bestTune


```


#2. KNN
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)

```

##Model
```{r}
df$Case_Status <- ifelse(df$Case_Status=="Bad",0,ifelse(df$Case_Status=="Medium",1,2))
df$Sex <- ifelse(df$Sex=="Female",0,1)
df$Patient_Followup_Status <- ifelse(df$Patient_Followup_Status=="Home Isolation/Ambulatory",0,1)
df$Contact <- ifelse(df$Contact=="Yes",0,1)
df$Pregnancy <- ifelse(df$Pregnancy=="Yes",0,1)
df$Intensive_care <- ifelse(df$Intensive_care=="Yes",0,1)
df$Intubation <- ifelse(df$Intubation=="Yes",0,1)
df$CT <- ifelse(df$CT=="Yes",0,1)
df$Pneumonia <- ifelse(df$Pneumonia=="Yes",0,1)


set.seed(123)
train_indeks <- createDataPartition(df$Case_Status, p = 0.8, list = FALSE, times = 1)

train <- df[train_indeks,]
test <- df[-train_indeks,]

train_x <- train %>% dplyr::select(-Case_Status)
train_y <- train$Case_Status

test_x <- test %>% dplyr::select(-Case_Status)
test_y <- test$Case_Status

training <- data.frame(train_x, Case_Status = train_y)



knn_train <- train
knn_test <- test

knn_train <- knn_train %>% dplyr::select(-c("Hospital","Notification_District","CT_Result", "Process_Status", "Province","District","Neighborhood"))
knn_test <- knn_test %>% dplyr::select(-c("Hospital","Notification_District","CT_Result", "Process_Status", "Province","District","Neighborhood"))


knn_train <- knn_train %>% dplyr:: select(-Case_Status)
knn_test <- knn_test %>% dplyr:: select(-Case_Status)


knn_fit <- knn(train = knn_train, test = knn_test, cl = train_y, k = 3)

knn_fit

summary(knn_fit)



```


## Tahmin

```{r}

class_err <- function(gercek, tahmin) {
  
  mean(gercek != tahmin)
  
}

class_err(test_y, knn_fit)


knn_fit3 <- knn(train = knn_train, test = knn_test, cl = train_y, k = 3)
knn_fit5 <- knn(train = knn_train, test = knn_test, cl = train_y, k = 5)
knn_fit10 <- knn(train = knn_train, test = knn_test, cl = train_y, k = 10)

summary(knn_fit3)
summary(knn_fit5)
summary(knn_fit10)

1-class_err(test_y, knn_fit3)
1-class_err(test_y, knn_fit5)
1-class_err(test_y, knn_fit10)

confusionMatrix(table(knn_fit3 ,test_y))
confusionMatrix(table(knn_fit5 ,test_y))
confusionMatrix(table(knn_fit10 ,test_y))

```

## Model Tuning

```{r}
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 3)

#,classProbs=TRUE,summaryFunction = twoClassSummary)

knn_tune<- train(Case_Status ~ ., 
                 data = training, 
                 method = "knn",
                 trControl = ctrl, 
                 preProcess = c("center","scale"),
                 tuneLength = 10
                 )

#ctrl <- trainControl(method = "cv", 
#                     number = 10,
#                     classProbs = TRUE,
#                     savePredictions = TRUE)

#knn_grid <- data.frame(k = c(4*(0:5)+1, 20*(1:5)+1, 50*(2:9)+1))

#knn_tune <- train(knn_train, train_y,
#                  method = "knn",
#                  
#                  preProc = c("center", "scale"),
#                  trControl = ctrl,
#                  tuneGrid = knn_grid)
#Output of kNN fit

knn_tune

plot(knn_tune)

knn_tuned <- knn(train = knn_train, test = knn_test, cl = train_y, k = 9)



knnPredict <- predict(knn_tune,test_x )
levels(knnPredict)
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(table(knn_tuned ,test_y))

#knnPredict_train <- predict(knn_tune,train_x )
#confusionMatrix(table(knn_tuned ,train_y))
#1-class_err(train_y, knnPredict_train)
```



#3. CART
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)

```
## Model

Veri Seti

```{r}

set.seed(123)
df<- df %>% dplyr::select(-c("Hospital","Notification_District","Province","District","Neighborhood"))
train_indeks <- createDataPartition(df$Case_Status, 
                                  p = .8, 
                                  list = FALSE, 
                                  times = 1)


train <- df[train_indeks,]
test  <- df[-train_indeks,]


train_x <- train %>% dplyr::select(-Case_Status)
train_y <- train$Case_Status
test_x <- test %>% dplyr::select(-Case_Status)
test_y <- test$Case_Status


#tek bir veri seti
training <- data.frame(train_x, Case_Status = train_y)

```




Model

```{r}

cart_tree <- tree(Case_Status~., data = train)

summary(cart_tree)

summary(cart_tree)$used




```

Agacin Gorsellestirilmesi

```{r}


plot(cart_tree)
text(cart_tree, pretty = 2)



```

rpart ile modelleme

```{r}
case_rpart <- rpart(Case_Status ~ ., data = train, method = "class")

plot(case_rpart)
text(case_rpart, pretty = 1)
prp(case_rpart, type = 0)
rpart.plot(case_rpart)

plotcp(case_rpart)

min_cp <- case_rpart$cptable[which.min(case_rpart$cptable[,"xerror"]), "CP"]
min_cp

prp(case_rpart, type = 1)


#budama  bulunan cp ile budama işlemi
case_rpart_prune <- prune(case_rpart, cp = min_cp)



prp(case_rpart_prune, type = 0)
rpart.plot(case_rpart_prune, type = 0)


```



## Tahmin


```{r}
predict(cart_tree, train_x, type = "class")

predict(cart_tree, train_x, type = "vector")



#cart_tree
tb <- table(predict(cart_tree, train_x, type = "class"), train_y)

confusionMatrix(tb, positive = "Kötü")

tb <- table(predict(cart_tree, test_x, type = "class"), test_y)

confusionMatrix(tb, positive = "Kötü")


#case_rpart_prune
tb <- table(predict(case_rpart_prune, train_x, type = "class"), train_y)

confusionMatrix(tb, positive = "Kötü")

tb <- table(predict(case_rpart_prune, test_x, type = "class"), test_y)

confusionMatrix(tb, positive = "Kötü")

```
## Model Tuning

CV ile budama yaparak model tuning islemleri:
```{r}
case_tree <- tree(Case_Status~ . , data = train)

set.seed(12312153)
case_tree_cv <- cv.tree(case_tree, FUN = prune.misclass, K = 10)
min_tree <- which.min(case_tree_cv$dev)

#ağacın indeksi
min_tree
#ağacın kaç nodedan oluştuğu (eski node: 10)
case_tree_cv$size[min_tree]

```

> Gorsel Incelenmesi

```{r}
par(mfrow = c(1,2))
plot(case_tree_cv)
plot(case_tree_cv$size, 
     case_tree_cv$dev / nrow(train), 
     type = "b",
     xlab = "Tree size/Number of Nodes", ylab = "CV Misclassification Rate")

```



> Bu Sonuclara Gore Agacin Budanmasi


```{r}

case_tree_prune <- prune.misclass(case_tree, best = 8)
summary(case_tree_prune)

plot(case_tree_prune)
text(case_tree_prune, pretty = 0)

```


> Sonuclarin Karsilastirilmasi

```{r}

tb <- table(predict(case_tree_prune, test_x, type = "class"), test_y)
confusionMatrix(tb, positive = "1")


```
## Caret ile Model Tuning

```{r}

#train control
set.seed(123)
ctrl <- trainControl(method="cv",
                     summaryFunction = multiClassSummary,
                     classProbs = TRUE)


cart_tune <- train(
  x = train_x,
  y = train_y,
  method = "rpart",
  tuneLength = 50,
  metric = "ROC",
  trControl = ctrl)

plot(cart_tune)
cart_tune$bestTune

tb <- table(predict(cart_tune, test_x), test_y)
confusionMatrix(tb, positive = "Bad")

tb <- table(predict(cart_tune, train_x), train_y)

confusionMatrix(tb, positive = "Bad")


```

#4. RANDOM FOREST
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)

```
> Veri Seti

```{r}

df<- df %>% dplyr::select(-c("Hospital","Notification_District","Province","District","Neighborhood"))

ncol(df)
set.seed(123)
train_indeks <- createDataPartition(df$Case_Status, 
                                  p = .8, 
                                  list = FALSE, 
                                  times = 1)


train <- df[train_indeks,]
test  <- df[-train_indeks,]


train_x <- train %>% dplyr::select(-Case_Status)
train_y <- train$Case_Status
test_x <- test %>% dplyr::select(-Case_Status)
test_y <- test$Case_Status


#tek bir veri seti
training <- data.frame(train_x, Case_Status = train_y)
```


## Model
```{r}

rf_fit <- randomForest(train_x, train_y, importance = TRUE)
rf_fit

#değişken önem düzeyleri
importance(rf_fit)

varImpPlot(rf_fit)

?randomForest
```


## Tahmin
```{r}
predict(rf_fit, test_x)

#train hatası
confusionMatrix(predict(rf_fit, train_x), train_y, positive = "1")

#test hatası
confusionMatrix(predict(rf_fit, test_x), test_y, positive = "1")

```







## Model Tuning


```{r}
#RANDOM SEARCH
control <- trainControl(method='repeatedcv', 
                        number = 10,
                        search = 'random')

#tunelenght ile 15 tane mtry degeri rastgele uretilecek 
set.seed(1)
rf_random <- train(Case_Status ~ .,
                   data = train,
                   method = 'rf',
                   metric = 'Accuracy',
                   tuneLength  = 15, 
                   trControl = control)




#GRID SEARCH
control <- trainControl(method='cv', 
                        number=10, 
                        search='grid')
 
tunegrid <- expand.grid(mtry = (1:10)) 

rf_gridsearch <- train(Case_Status ~ ., 
                       data = train,
                       method = 'rf',
                       metric = 'Accuracy',
                       tuneGrid = tunegrid)


rf_random$results
rf_gridsearch

plot(rf_random)
plot(rf_gridsearch)

confusionMatrix(predict(rf_random, train_x), train_y, positive = "0")

confusionMatrix(predict(rf_random, test_x), test_y, positive = "0")



```


#5. GBM
```{r}
df<-Veri_normal_oksijenli4
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hospital","Sex","Patient_Followup_Status", "Case_Status","Contact","Pregnancy","Notification_District","Intensive_care","Intubation","Age","CT_Result","CT","Pneumonia", "Process_Status", "Province","District","Neighborhood","Ferritin","CRP","Oxygen")

#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Pregnancy`))
df$`Pregnancy`[indeks_eksikgebelik] <- "No"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`CT_Result`))
df$`CT_Result`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)

```

```{r}
df<- df %>% dplyr::select(-c("Hospital","Notification_District","CT_Result","Process_Status", "Province","District","Neighborhood"))


df$Case_Status <- ifelse(df$Case_Status=="Bad",0,ifelse(df$Case_Status=="Medium",1,2))
df$Sex <- ifelse(df$Sex=="Female",0,1)
df$Patient_Followup_Status <- ifelse(df$Patient_Followup_Status=="Home Isolation/Ambulatory",0,1)
df$Contact <- ifelse(df$Contact=="Yes",0,1)
df$Pregnancy <- ifelse(df$Pregnancy=="Yes",0,1)
df$Intensive_care <- ifelse(df$Intensive_care=="Yes",0,1)
df$Intubation <- ifelse(df$Intubation=="Yes",0,1)
df$CT <- ifelse(df$CT=="Yes",0,1)
df$Pneumonia <- ifelse(df$Pneumonia=="Yes",0,1)

set.seed(123)
train_indeks <- createDataPartition(df$Case_Status, 
                                  p = .8, 
                                  list = FALSE, 
                                  times = 1)


train <- df[train_indeks,]
test  <- df[-train_indeks,]


train_x <- train %>% dplyr::select(-Case_Status)
train_y <- train$Case_Status
test_x <- test %>% dplyr::select(-Case_Status)
test_y <- test$Case_Status


#tek bir veri seti
training <- data.frame(train_x, Case_Status = train_y)


```

## Model 
```{r}

train$Case_Status<- as.numeric(train$Case_Status)
train <- transform(train, Case_Status = Case_Status - 1)
df$`Case_Status`<-as.factor(df$`Case_Status`)

gbm_fit <- gbm(Case_Status~., data = train, 
               shrinkage = 0.01,
               distribution = "bernoulli",
               cv.folds = 5,
               n.trees = 3000,
               verbose = F)

summary(gbm_fit)

#gbm.perf(gbm_fit, method = "cv")
#plot.gbm(gbm_fit,  1, gbm.perf(gbm_fit, method = "cv"))
```


## Tahmin
```{r}

pred <- predict.gbm(gbm_fit, test_x, type = "response")
head(pred)

```

## Model Tuning
```{r}
set.seed(123)
ctrl <- trainControl(method="cv", number=10)


gbm_grid <- expand.grid(
  interaction.depth = seq(1, 7, by = 2),#derinlik para.
   n.trees = seq(100, 4000, by = 500),#ağaç sayısı
    shrinkage = c(0.01, 0.1),#daraltma adım boyu, öğrenme katsayısı
    n.minobsinnode = c(1:10))#bırakılacak gözlem sayısı


gbm_grid <- data.frame(n.trees=2000, 
                       shrinkage=0.01, 
                       interaction.depth=1, 
                       n.minobsinnode=1)

gbm_tune <- train(
  factor(Case_Status) ~., data = train,
  method = "gbm",
  distribution = "bernoulli",
  trControl = ctrl,
  verbose = F,
  tuneGrid = gbm_grid
)
getTrainPerf(gbm_tune)


pred<- predict(gbm_tune, test_x)
gbm_class <- ifelse(pred == 0, "High", "Low")
test_y

confusionMatrix(factor(gbm_class), test_y)

```

#XGBoost
```{r}
df<-Veri_normal_oksijenli
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hastane_Adi","Cinsiyet","Hasta_Takip_Durumu", "Vaka_Durumu","Temaslı_mi","Gebe_Mi","Bildirim_İlcesi","Yogun_Bakimda_Mi","Entübasyon_Var_mi","Yas","BT_Sonucu","BT","Pnomoni", "Sürec_Durumu", "Mernis_il","Mernis_ilce","Mernis_mahalle","Ferritin","CRP","Oksijen")
#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Gebe_Mi`))
df$`Gebe_Mi`[indeks_eksikgebelik] <- "Hayır"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`BT_Sonucu`))
df$`BT_Sonucu`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)

```
```{r}
#df<-df %>% dplyr::select(c("Yas","Oksijen","Ferritin","CRP","Vaka_Durumu"))
df<- df %>% dplyr::select(-c("Hastane_Adi","Bildirim_İlcesi","Mernis_il","Mernis_ilce","Mernis_mahalle",,"Hasta_Takip_Durumu", "BT_Sonucu", "Sürec_Durumu"))
df$Vaka_Durumu <- ifelse(df$Vaka_Durumu=="Kötü",0,ifelse(df$Vaka_Durumu=="Orta",1,2))
df$Cinsiyet <- ifelse(df$Cinsiyet=="Kadın",0,1)
df$Hasta_Takip_Durumu <- ifelse(df$Hasta_Takip_Durumu=="Evde İzolasyon/Ayaktan",0,1)
df$Temaslı_mi <- ifelse(df$Temaslı_mi=="Evet",0,1)
df$Gebe_Mi <- ifelse(df$Gebe_Mi=="Evet",0,1)
df$Yogun_Bakimda_Mi <- ifelse(df$Yogun_Bakimda_Mi=="Evet",0,1)
df$Entübasyon_Var_mi <- ifelse(df$Entübasyon_Var_mi=="Evet",0,1)
df$BT <- ifelse(df$BT=="VAR",0,1)
df$Pnomoni <- ifelse(df$Pnomoni=="VAR",0,1)

set.seed(123)
train_indeks <- createDataPartition(df$Vaka_Durumu, 
                                  p = .8, 
                                  list = FALSE, 
                                  times = 1)


train <- df[train_indeks,]
test  <- df[-train_indeks,]


train_x <- train %>% dplyr::select(-Vaka_Durumu)
train_y <- train$Vaka_Durumu
test_x <- test %>% dplyr::select(-Vaka_Durumu)
test_y <- test$Vaka_Durumu


#tek bir veri seti
training <- data.frame(train_x, Vaka_Durumu = train_y)
```

## Model 


```{r}

train_y <- as.numeric(train_y)-1
dtrain <- xgb.DMatrix(data = as.matrix(train_x), label = train_y)

test_y <- as.numeric(test_y)-1
dtest <- xgb.DMatrix(data = as.matrix(test_x), label = test_y)


xgb_fit <- xgboost(data = dtrain, 
        max.depth = 2,
        eta = 1,
        ntread = 2,
        nrounds = 5,
        objective = "multi:softprob",
        verbose = 1)
```



> Performans Degerlendirme Metrigi Eklenmesi

```{r}

bst <- xgb.train(data = dtrain , 
          max.depth = 2,
          eta = 1,
          ntread = 2,
          nrounds = 5,
          eval.metric = "error",
          eval.metric = "logloss",
          objective = "multi:softmax")
help(xgb.train)
```


> Degisken Onem Duzeyleri ve Agac Yapilari

Degisken Onem Duzeyleri
```{r}

mm <- xgb.importance(model = bst)
xgb.plot.importance(mm)

```


Agac Yapilarinin Gorulmesi
```{r}

xgb.dump(bst, with_stats = T)
xgb.plot.tree(model = bst)
```

#YSA

> Veri Seti

```{r}
df$Vaka_Durumu <- ifelse(df$Vaka_Durumu=="Kötü",0,ifelse(df$Vaka_Durumu=="Orta",1,2))

table(df$Vaka_Durumu) #Frekans

table(df$Vaka_Durumu) / length(df$Vaka_Durumu) #Oranları

freq(df) #Kategorik değişkenlerin görselleştirmesi

#Standartlaştırma işlemi
scale01 <- function(x) {
    (x - min(x))/(max(x) - min(x))
}

df <- df %>% mutate(Yas = scale01(Yas),
                    Ferritin = scale01(Ferritin),
                    CRP = scale01(CRP))



train_indeks <- createDataPartition(df$Vaka_Durumu, 
                                  p = .7, 
                                  list = FALSE, 
                                  times = 1)

train <- df[train_indeks,]
test  <- df[-train_indeks,]

ysa_train_x <- train %>% dplyr::select(-Vaka_Durumu)
ysa_train_y <- train$Vaka_Durumu

ysa_test_x <- test %>% dplyr::select(-Vaka_Durumu)
ysa_test_y <- test$Vaka_Durumu

levels(train$Vaka_Durumu) <- make.names(levels(factor(train$Vaka_Durumu)))
ysa_train_y <- train$Vaka_Durumu

```

## Model 

```{r}
set.seed(800)
nnet_fit <- nnet(Vaka_Durumu ~., df, size = 3, decay = 0.1)

```

## Tahmin

```{r}
head(predict(nnet_fit, ysa_train_x))
head(predict(nnet_fit, ysa_train_x, type = "class"))

pred <- predict(nnet_fit, ysa_test_x, type = "class")
pred 

confusionMatrix(factor(pred), ysa_test_y, positive = "1")




```



#SVM
```{r}
df<-Veri_normal_oksijenli
df$`Hastane Adı`<-as.factor(df$`Hastane Adı`)
df$`Cinsiyet`<-as.factor(df$`Cinsiyet`)
df$`Vaka Kaynağı`<-as.factor(df$`Vaka Kaynağı`)
df$`Hasta Takip Durumu`<-as.factor(df$`Hasta Takip Durumu`)
df$`Vaka Durumu`<-as.factor(df$`Vaka Durumu`)
df$`Temaslı Mı?`<-as.factor(df$`Temaslı Mı?`)
df$`Gebe Mi?`<-as.factor(df$`Gebe Mi?`)
df$`Bildirim İlçesi`<-as.factor(df$`Bildirim İlçesi`)
df$`Yoğun Bakımda Mı?`<-as.factor(df$`Yoğun Bakımda Mı?`)
df$`Entübasyon Var Mı?`<-as.factor(df$`Entübasyon Var Mı?`)
df$`BT Sonucu`<-as.factor(df$`BT Sonucu`)
df$`BT`<-as.factor(df$`BT`)
df$`Pnömoni`<-as.factor(df$`Pnömoni`)
df$`Süreç Durumu`<-as.factor(df$`Süreç Durumu`)
df$`Mernis İl`<-as.factor(df$`Mernis İl`)
df$`Mernis İlçe`<-as.factor(df$`Mernis İlçe`)
df$`Mernis Mahalle`<-as.factor(df$`Mernis Mahalle`)

df<-df %>% dplyr :: select(-c("Vaka Kaynağı"))

names(df) <- c("Hastane_Adi","Cinsiyet","Hasta_Takip_Durumu", "Vaka_Durumu","Temaslı_mi","Gebe_Mi","Bildirim_İlcesi","Yogun_Bakimda_Mi","Entübasyon_Var_mi","Yas","BT_Sonucu","BT","Pnomoni", "Sürec_Durumu", "Mernis_il","Mernis_ilce","Mernis_mahalle","Ferritin","CRP","Oksijen")
#Eksik Gebelik Verilerinin Doldurulması
indeks_eksikgebelik <- which(is.na(df$`Gebe_Mi`))
df$`Gebe_Mi`[indeks_eksikgebelik] <- "Hayır"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Eksik BT Sonuçlarının Doldurulması
indeks_eksikbtsonuc <- which(is.na(df$`BT_Sonucu`))
df$`BT_Sonucu`[indeks_eksikbtsonuc] <- "Normal"

indeks_eksikveri <- which(is.na(df))
length(indeks_eksikveri)
#Gebeliklerin doldurulmasından sonra eksik gözlemleri silersek
df<-na.omit(df)
nrow(df)
indeks_son <- which(is.na(df))
length(indeks_son)

```


```{r}
df$Vaka_Durumu <- ifelse(df$Vaka_Durumu=="Kötü",0,ifelse(df$Vaka_Durumu=="Orta",1,2))
df$Cinsiyet <- ifelse(df$Cinsiyet=="Kadın",0,1)
df$Hasta_Takip_Durumu <- ifelse(df$Hasta_Takip_Durumu=="Evde İzolasyon/Ayaktan",0,1)
df$Temaslı_mi <- ifelse(df$Temaslı_mi=="Evet",0,1)
df$Gebe_Mi <- ifelse(df$Gebe_Mi=="Evet",0,1)
df$Yogun_Bakimda_Mi <- ifelse(df$Yogun_Bakimda_Mi=="Evet",0,1)
df$Entübasyon_Var_mi <- ifelse(df$Entübasyon_Var_mi=="Evet",0,1)
df$BT <- ifelse(df$BT=="VAR",0,1)
df$Pnomoni <- ifelse(df$Pnomoni=="VAR",0,1)


df <- df %>% dplyr::select(-c("Hastane_Adi","Bildirim_İlcesi","BT_Sonucu", "Sürec_Durumu", "Mernis_il","Mernis_ilce","Mernis_mahalle"))


set.seed(123)
train_indeks <- createDataPartition(df$Vaka_Durumu, 
                                  p = .8, 
                                  list = FALSE, 
                                  times = 1)


train <- df[train_indeks,]
test  <- df[-train_indeks,]


train_x <- train %>% dplyr::select(-Vaka_Durumu)
train_y <- train$Vaka_Durumu
test_x <- test %>% dplyr::select(-Vaka_Durumu)
test_y <- test$Vaka_Durumu


classifier = svm(formula = Vaka_Durumu ~ ., data=train, type='C-classification', kernel='linear')

y_pred <- as.vector(predict(classifier, newdata = test_x))


cm <- table(test_y, y_pred)

```

```{r}
##test-train


set.seed(123)
train_indeks <- createDataPartition(df$Case_Status, 
                                  p = .8, 
                                  list = FALSE, 
                                  times = 1)


train <- df[train_indeks,]
test  <- df[-train_indeks,]


train_x <- train %>% dplyr::select(-Case_Status)
train_y <- train$Case_Status
test_x <- test %>% dplyr::select(-Case_Status)
test_y <- test$Case_Status


classifier1 = svm(formula = Case_Status ~ ., data=train, type='C-classification', kernel='linear')
y_pred1 <- as.vector(predict(classifier1, newdata = test_x))
cm1 <- table(test_y, y_pred1)

classifier2 = svm(formula = Case_Status ~ ., data=train, type='C-classification', kernel='radial')
y_pred2 <- as.vector(predict(classifier2, newdata = test_x))
cm2 <- table(test_y, y_pred2)

cm1
cm2

cfm1 <- tidy(cm1)
cfm2 <- tidy(cm2)

defaultSummary(data.frame(obs = test_y, 
                          pred = predict(classifier1, test_x)))


##cm tabloları

{r}
install.packages("cvms")
library(cvms)
library(broom)    # tidy()
library(tibble)   # tibble()

set.seed(1)

plot_confusion_matrix(cfm1, 
                      target_col = "test_y", 
                      prediction_col = "y_pred1",
                      counts_col = "n")


set.seed(1)

plot_confusion_matrix(cfm2, 
                      target_col = "test_y", 
                      prediction_col = "y_pred2",
                      counts_col = "n")

y_pred <- as.vector(predict(classifier, newdata = test_x))


cm <- table(test_y, y_pred)


confusionMatrix(predict(classifier1, train_x), train_y, positive = "0")

confusionMatrix(predict(classifier1, test_x), test_y, positive = "0")


confusionMatrix(predict(classifier2, train_x), train_y, positive = "0")

confusionMatrix(predict(classifier2, test_x), test_y, positive = "0")

```

